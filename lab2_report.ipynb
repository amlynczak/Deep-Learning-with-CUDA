{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMv62VUFx8sltmgUq14TC8D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["importing necessary items for our models"],"metadata":{"id":"jLx95iprQZG_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FH1zKkPsPpCt"},"outputs":[],"source":["import tensorflow\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import SGD\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","source":["(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVlHjHLYQ_DL","executionInfo":{"status":"ok","timestamp":1679068236407,"user_tz":-60,"elapsed":715,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"740d21ff-45f4-4dc8-8b10-8f5e968320aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["giving our model some data to work on"],"metadata":{"id":"GbSurxKLRTOG"}},{"cell_type":"code","source":["plt.figure(figsize=(2,2))\n","for k in range(12):\n","    plt.subplot(3, 4, k+1)\n","    plt.imshow(X_train[k], cmap='Greys')\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"A5cb4JAQRKZ5","executionInfo":{"status":"ok","timestamp":1679068290929,"user_tz":-60,"elapsed":1864,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"e246aa0e-b719-432b-a13a-ad39e2b53862"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 144x144 with 12 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["training itself"],"metadata":{"id":"zqg0lZb5RX-d"}},{"cell_type":"code","source":["y_train[0:12]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-T1rZ7erRKna","executionInfo":{"status":"ok","timestamp":1679068342257,"user_tz":-60,"elapsed":266,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"32518698-8569-46b0-db6e-05f336f0ba90"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["X_train = X_train.reshape(60000, 784).astype('float32')\n","X_valid = X_valid.reshape(10000, 784).astype('float32')"],"metadata":{"id":"_WL8b0OsRe4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train /= 255\n","X_valid /= 255"],"metadata":{"id":"GusaUmOcRiLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_classes = 10\n","y_train = to_categorical(y_train, n_classes)\n","y_valid = to_categorical(y_valid, n_classes)"],"metadata":{"id":"hywrgTOcRoI3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["building first model"],"metadata":{"id":"DuNTKf0BR4zY"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n","model.add(Dense(10, activation='softmax'))"],"metadata":{"id":"VlNgp-0oQ3N-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vL6xTI1R-Co","executionInfo":{"status":"ok","timestamp":1679068491261,"user_tz":-60,"elapsed":276,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"57cd8bc3-b7c5-4422-e2a5-8e44412fee5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 64)                50240     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 50,890\n","Trainable params: 50,890\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"],"metadata":{"id":"_NqP07wZSDRd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJoH-lLoSHiN","executionInfo":{"status":"ok","timestamp":1679068973051,"user_tz":-60,"elapsed":443398,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"aaafe42a-4666-45bc-a64d-3f43d29e3bfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0946 - accuracy: 0.1004 - val_loss: 0.0934 - val_accuracy: 0.1070\n","Epoch 2/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0929 - accuracy: 0.1077 - val_loss: 0.0923 - val_accuracy: 0.1226\n","Epoch 3/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0919 - accuracy: 0.1269 - val_loss: 0.0914 - val_accuracy: 0.1446\n","Epoch 4/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0912 - accuracy: 0.1501 - val_loss: 0.0908 - val_accuracy: 0.1651\n","Epoch 5/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0906 - accuracy: 0.1701 - val_loss: 0.0903 - val_accuracy: 0.1827\n","Epoch 6/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0901 - accuracy: 0.1857 - val_loss: 0.0899 - val_accuracy: 0.1980\n","Epoch 7/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.1990 - val_loss: 0.0895 - val_accuracy: 0.2079\n","Epoch 8/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0894 - accuracy: 0.2105 - val_loss: 0.0892 - val_accuracy: 0.2187\n","Epoch 9/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0891 - accuracy: 0.2212 - val_loss: 0.0889 - val_accuracy: 0.2307\n","Epoch 10/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0888 - accuracy: 0.2321 - val_loss: 0.0886 - val_accuracy: 0.2428\n","Epoch 11/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0885 - accuracy: 0.2502 - val_loss: 0.0883 - val_accuracy: 0.2637\n","Epoch 12/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.2738 - val_loss: 0.0880 - val_accuracy: 0.2915\n","Epoch 13/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0879 - accuracy: 0.2975 - val_loss: 0.0877 - val_accuracy: 0.3214\n","Epoch 14/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0876 - accuracy: 0.3248 - val_loss: 0.0874 - val_accuracy: 0.3495\n","Epoch 15/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0874 - accuracy: 0.3508 - val_loss: 0.0872 - val_accuracy: 0.3744\n","Epoch 16/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0871 - accuracy: 0.3758 - val_loss: 0.0869 - val_accuracy: 0.3961\n","Epoch 17/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0868 - accuracy: 0.3988 - val_loss: 0.0866 - val_accuracy: 0.4160\n","Epoch 18/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0865 - accuracy: 0.4208 - val_loss: 0.0863 - val_accuracy: 0.4319\n","Epoch 19/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.4365 - val_loss: 0.0860 - val_accuracy: 0.4471\n","Epoch 20/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0859 - accuracy: 0.4477 - val_loss: 0.0857 - val_accuracy: 0.4565\n","Epoch 21/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0856 - accuracy: 0.4563 - val_loss: 0.0854 - val_accuracy: 0.4658\n","Epoch 22/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0853 - accuracy: 0.4622 - val_loss: 0.0850 - val_accuracy: 0.4709\n","Epoch 23/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0850 - accuracy: 0.4664 - val_loss: 0.0847 - val_accuracy: 0.4764\n","Epoch 24/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0846 - accuracy: 0.4702 - val_loss: 0.0844 - val_accuracy: 0.4807\n","Epoch 25/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.4737 - val_loss: 0.0840 - val_accuracy: 0.4862\n","Epoch 26/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.4788 - val_loss: 0.0837 - val_accuracy: 0.4879\n","Epoch 27/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0836 - accuracy: 0.4803 - val_loss: 0.0833 - val_accuracy: 0.4909\n","Epoch 28/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0832 - accuracy: 0.4834 - val_loss: 0.0829 - val_accuracy: 0.4932\n","Epoch 29/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0828 - accuracy: 0.4862 - val_loss: 0.0825 - val_accuracy: 0.4951\n","Epoch 30/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0824 - accuracy: 0.4895 - val_loss: 0.0821 - val_accuracy: 0.4973\n","Epoch 31/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.4913 - val_loss: 0.0817 - val_accuracy: 0.4998\n","Epoch 32/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.4933 - val_loss: 0.0813 - val_accuracy: 0.5026\n","Epoch 33/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0812 - accuracy: 0.4968 - val_loss: 0.0809 - val_accuracy: 0.5051\n","Epoch 34/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0808 - accuracy: 0.4990 - val_loss: 0.0804 - val_accuracy: 0.5079\n","Epoch 35/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0804 - accuracy: 0.5033 - val_loss: 0.0800 - val_accuracy: 0.5114\n","Epoch 36/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0799 - accuracy: 0.5059 - val_loss: 0.0796 - val_accuracy: 0.5148\n","Epoch 37/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0795 - accuracy: 0.5092 - val_loss: 0.0791 - val_accuracy: 0.5173\n","Epoch 38/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.5122 - val_loss: 0.0786 - val_accuracy: 0.5211\n","Epoch 39/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0786 - accuracy: 0.5169 - val_loss: 0.0782 - val_accuracy: 0.5252\n","Epoch 40/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0781 - accuracy: 0.5215 - val_loss: 0.0777 - val_accuracy: 0.5294\n","Epoch 41/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0776 - accuracy: 0.5251 - val_loss: 0.0772 - val_accuracy: 0.5331\n","Epoch 42/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.5281 - val_loss: 0.0767 - val_accuracy: 0.5378\n","Epoch 43/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.5329 - val_loss: 0.0762 - val_accuracy: 0.5414\n","Epoch 44/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0762 - accuracy: 0.5366 - val_loss: 0.0757 - val_accuracy: 0.5450\n","Epoch 45/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0757 - accuracy: 0.5398 - val_loss: 0.0752 - val_accuracy: 0.5483\n","Epoch 46/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0752 - accuracy: 0.5444 - val_loss: 0.0747 - val_accuracy: 0.5514\n","Epoch 47/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0747 - accuracy: 0.5484 - val_loss: 0.0742 - val_accuracy: 0.5551\n","Epoch 48/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0742 - accuracy: 0.5519 - val_loss: 0.0736 - val_accuracy: 0.5588\n","Epoch 49/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0736 - accuracy: 0.5560 - val_loss: 0.0731 - val_accuracy: 0.5626\n","Epoch 50/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.5597 - val_loss: 0.0726 - val_accuracy: 0.5652\n","Epoch 51/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0726 - accuracy: 0.5634 - val_loss: 0.0721 - val_accuracy: 0.5686\n","Epoch 52/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0721 - accuracy: 0.5674 - val_loss: 0.0715 - val_accuracy: 0.5717\n","Epoch 53/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.5699 - val_loss: 0.0710 - val_accuracy: 0.5743\n","Epoch 54/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0710 - accuracy: 0.5738 - val_loss: 0.0705 - val_accuracy: 0.5779\n","Epoch 55/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.5769 - val_loss: 0.0699 - val_accuracy: 0.5817\n","Epoch 56/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0700 - accuracy: 0.5798 - val_loss: 0.0694 - val_accuracy: 0.5857\n","Epoch 57/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.5831 - val_loss: 0.0689 - val_accuracy: 0.5886\n","Epoch 58/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0690 - accuracy: 0.5859 - val_loss: 0.0683 - val_accuracy: 0.5916\n","Epoch 59/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0684 - accuracy: 0.5892 - val_loss: 0.0678 - val_accuracy: 0.5944\n","Epoch 60/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0679 - accuracy: 0.5919 - val_loss: 0.0673 - val_accuracy: 0.5979\n","Epoch 61/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0674 - accuracy: 0.5951 - val_loss: 0.0668 - val_accuracy: 0.6008\n","Epoch 62/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0669 - accuracy: 0.5976 - val_loss: 0.0662 - val_accuracy: 0.6042\n","Epoch 63/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.6007 - val_loss: 0.0657 - val_accuracy: 0.6069\n","Epoch 64/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0658 - accuracy: 0.6034 - val_loss: 0.0652 - val_accuracy: 0.6089\n","Epoch 65/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.6061 - val_loss: 0.0647 - val_accuracy: 0.6116\n","Epoch 66/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.6094 - val_loss: 0.0641 - val_accuracy: 0.6136\n","Epoch 67/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0643 - accuracy: 0.6122 - val_loss: 0.0636 - val_accuracy: 0.6164\n","Epoch 68/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0638 - accuracy: 0.6147 - val_loss: 0.0631 - val_accuracy: 0.6196\n","Epoch 69/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0633 - accuracy: 0.6172 - val_loss: 0.0626 - val_accuracy: 0.6230\n","Epoch 70/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0628 - accuracy: 0.6201 - val_loss: 0.0621 - val_accuracy: 0.6256\n","Epoch 71/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0623 - accuracy: 0.6233 - val_loss: 0.0616 - val_accuracy: 0.6283\n","Epoch 72/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0618 - accuracy: 0.6265 - val_loss: 0.0611 - val_accuracy: 0.6321\n","Epoch 73/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0613 - accuracy: 0.6295 - val_loss: 0.0606 - val_accuracy: 0.6358\n","Epoch 74/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0608 - accuracy: 0.6324 - val_loss: 0.0601 - val_accuracy: 0.6388\n","Epoch 75/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.6353 - val_loss: 0.0596 - val_accuracy: 0.6426\n","Epoch 76/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.6381 - val_loss: 0.0591 - val_accuracy: 0.6442\n","Epoch 77/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.6417 - val_loss: 0.0587 - val_accuracy: 0.6476\n","Epoch 78/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0589 - accuracy: 0.6446 - val_loss: 0.0582 - val_accuracy: 0.6511\n","Epoch 79/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.6475 - val_loss: 0.0577 - val_accuracy: 0.6532\n","Epoch 80/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0580 - accuracy: 0.6504 - val_loss: 0.0572 - val_accuracy: 0.6571\n","Epoch 81/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0576 - accuracy: 0.6535 - val_loss: 0.0568 - val_accuracy: 0.6600\n","Epoch 82/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0571 - accuracy: 0.6572 - val_loss: 0.0563 - val_accuracy: 0.6642\n","Epoch 83/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0567 - accuracy: 0.6603 - val_loss: 0.0559 - val_accuracy: 0.6671\n","Epoch 84/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0562 - accuracy: 0.6632 - val_loss: 0.0554 - val_accuracy: 0.6706\n","Epoch 85/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0558 - accuracy: 0.6661 - val_loss: 0.0550 - val_accuracy: 0.6740\n","Epoch 86/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0554 - accuracy: 0.6699 - val_loss: 0.0546 - val_accuracy: 0.6778\n","Epoch 87/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0549 - accuracy: 0.6736 - val_loss: 0.0541 - val_accuracy: 0.6816\n","Epoch 88/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.6769 - val_loss: 0.0537 - val_accuracy: 0.6860\n","Epoch 89/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0541 - accuracy: 0.6797 - val_loss: 0.0533 - val_accuracy: 0.6892\n","Epoch 90/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.6832 - val_loss: 0.0529 - val_accuracy: 0.6921\n","Epoch 91/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0533 - accuracy: 0.6865 - val_loss: 0.0524 - val_accuracy: 0.6963\n","Epoch 92/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0529 - accuracy: 0.6898 - val_loss: 0.0520 - val_accuracy: 0.7005\n","Epoch 93/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0525 - accuracy: 0.6928 - val_loss: 0.0516 - val_accuracy: 0.7044\n","Epoch 94/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0521 - accuracy: 0.6961 - val_loss: 0.0512 - val_accuracy: 0.7075\n","Epoch 95/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0517 - accuracy: 0.6995 - val_loss: 0.0509 - val_accuracy: 0.7109\n","Epoch 96/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0513 - accuracy: 0.7026 - val_loss: 0.0505 - val_accuracy: 0.7138\n","Epoch 97/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0510 - accuracy: 0.7055 - val_loss: 0.0501 - val_accuracy: 0.7171\n","Epoch 98/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.7084 - val_loss: 0.0497 - val_accuracy: 0.7205\n","Epoch 99/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0502 - accuracy: 0.7113 - val_loss: 0.0493 - val_accuracy: 0.7224\n","Epoch 100/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.7135 - val_loss: 0.0490 - val_accuracy: 0.7257\n","Epoch 101/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.7164 - val_loss: 0.0486 - val_accuracy: 0.7289\n","Epoch 102/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0491 - accuracy: 0.7196 - val_loss: 0.0482 - val_accuracy: 0.7325\n","Epoch 103/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0488 - accuracy: 0.7219 - val_loss: 0.0479 - val_accuracy: 0.7346\n","Epoch 104/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0484 - accuracy: 0.7244 - val_loss: 0.0475 - val_accuracy: 0.7369\n","Epoch 105/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0481 - accuracy: 0.7270 - val_loss: 0.0472 - val_accuracy: 0.7386\n","Epoch 106/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0478 - accuracy: 0.7293 - val_loss: 0.0469 - val_accuracy: 0.7408\n","Epoch 107/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0474 - accuracy: 0.7319 - val_loss: 0.0465 - val_accuracy: 0.7430\n","Epoch 108/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0471 - accuracy: 0.7341 - val_loss: 0.0462 - val_accuracy: 0.7452\n","Epoch 109/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0468 - accuracy: 0.7359 - val_loss: 0.0459 - val_accuracy: 0.7480\n","Epoch 110/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0465 - accuracy: 0.7382 - val_loss: 0.0455 - val_accuracy: 0.7502\n","Epoch 111/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0462 - accuracy: 0.7399 - val_loss: 0.0452 - val_accuracy: 0.7515\n","Epoch 112/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0459 - accuracy: 0.7419 - val_loss: 0.0449 - val_accuracy: 0.7538\n","Epoch 113/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.7442 - val_loss: 0.0446 - val_accuracy: 0.7561\n","Epoch 114/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0452 - accuracy: 0.7462 - val_loss: 0.0443 - val_accuracy: 0.7584\n","Epoch 115/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0449 - accuracy: 0.7483 - val_loss: 0.0440 - val_accuracy: 0.7603\n","Epoch 116/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0447 - accuracy: 0.7503 - val_loss: 0.0437 - val_accuracy: 0.7627\n","Epoch 117/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.7525 - val_loss: 0.0434 - val_accuracy: 0.7650\n","Epoch 118/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0441 - accuracy: 0.7545 - val_loss: 0.0431 - val_accuracy: 0.7669\n","Epoch 119/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0438 - accuracy: 0.7569 - val_loss: 0.0428 - val_accuracy: 0.7687\n","Epoch 120/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.7587 - val_loss: 0.0425 - val_accuracy: 0.7714\n","Epoch 121/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0432 - accuracy: 0.7607 - val_loss: 0.0423 - val_accuracy: 0.7736\n","Epoch 122/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.7628 - val_loss: 0.0420 - val_accuracy: 0.7754\n","Epoch 123/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0427 - accuracy: 0.7649 - val_loss: 0.0417 - val_accuracy: 0.7774\n","Epoch 124/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0424 - accuracy: 0.7672 - val_loss: 0.0414 - val_accuracy: 0.7797\n","Epoch 125/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0422 - accuracy: 0.7694 - val_loss: 0.0412 - val_accuracy: 0.7817\n","Epoch 126/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0419 - accuracy: 0.7713 - val_loss: 0.0409 - val_accuracy: 0.7838\n","Epoch 127/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0417 - accuracy: 0.7734 - val_loss: 0.0406 - val_accuracy: 0.7854\n","Epoch 128/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0414 - accuracy: 0.7751 - val_loss: 0.0404 - val_accuracy: 0.7882\n","Epoch 129/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0411 - accuracy: 0.7771 - val_loss: 0.0401 - val_accuracy: 0.7897\n","Epoch 130/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0409 - accuracy: 0.7791 - val_loss: 0.0399 - val_accuracy: 0.7923\n","Epoch 131/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0407 - accuracy: 0.7813 - val_loss: 0.0396 - val_accuracy: 0.7938\n","Epoch 132/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.7833 - val_loss: 0.0394 - val_accuracy: 0.7959\n","Epoch 133/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0402 - accuracy: 0.7854 - val_loss: 0.0392 - val_accuracy: 0.7974\n","Epoch 134/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0399 - accuracy: 0.7869 - val_loss: 0.0389 - val_accuracy: 0.7986\n","Epoch 135/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.7884 - val_loss: 0.0387 - val_accuracy: 0.8008\n","Epoch 136/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.7901 - val_loss: 0.0384 - val_accuracy: 0.8031\n","Epoch 137/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0392 - accuracy: 0.7921 - val_loss: 0.0382 - val_accuracy: 0.8044\n","Epoch 138/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0390 - accuracy: 0.7937 - val_loss: 0.0380 - val_accuracy: 0.8068\n","Epoch 139/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.7953 - val_loss: 0.0378 - val_accuracy: 0.8078\n","Epoch 140/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0386 - accuracy: 0.7970 - val_loss: 0.0375 - val_accuracy: 0.8099\n","Epoch 141/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0384 - accuracy: 0.7983 - val_loss: 0.0373 - val_accuracy: 0.8122\n","Epoch 142/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.7998 - val_loss: 0.0371 - val_accuracy: 0.8136\n","Epoch 143/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0379 - accuracy: 0.8011 - val_loss: 0.0369 - val_accuracy: 0.8153\n","Epoch 144/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0377 - accuracy: 0.8028 - val_loss: 0.0367 - val_accuracy: 0.8166\n","Epoch 145/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0375 - accuracy: 0.8045 - val_loss: 0.0365 - val_accuracy: 0.8178\n","Epoch 146/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.8059 - val_loss: 0.0363 - val_accuracy: 0.8191\n","Epoch 147/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.8074 - val_loss: 0.0360 - val_accuracy: 0.8204\n","Epoch 148/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0369 - accuracy: 0.8089 - val_loss: 0.0358 - val_accuracy: 0.8215\n","Epoch 149/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0367 - accuracy: 0.8101 - val_loss: 0.0356 - val_accuracy: 0.8224\n","Epoch 150/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.8114 - val_loss: 0.0354 - val_accuracy: 0.8233\n","Epoch 151/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.8125 - val_loss: 0.0352 - val_accuracy: 0.8243\n","Epoch 152/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0361 - accuracy: 0.8134 - val_loss: 0.0351 - val_accuracy: 0.8261\n","Epoch 153/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0359 - accuracy: 0.8150 - val_loss: 0.0349 - val_accuracy: 0.8266\n","Epoch 154/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0358 - accuracy: 0.8159 - val_loss: 0.0347 - val_accuracy: 0.8276\n","Epoch 155/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0356 - accuracy: 0.8170 - val_loss: 0.0345 - val_accuracy: 0.8290\n","Epoch 156/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0354 - accuracy: 0.8182 - val_loss: 0.0343 - val_accuracy: 0.8305\n","Epoch 157/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.8193 - val_loss: 0.0341 - val_accuracy: 0.8321\n","Epoch 158/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0350 - accuracy: 0.8205 - val_loss: 0.0339 - val_accuracy: 0.8325\n","Epoch 159/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.8217 - val_loss: 0.0338 - val_accuracy: 0.8338\n","Epoch 160/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0347 - accuracy: 0.8229 - val_loss: 0.0336 - val_accuracy: 0.8343\n","Epoch 161/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0345 - accuracy: 0.8237 - val_loss: 0.0334 - val_accuracy: 0.8353\n","Epoch 162/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0343 - accuracy: 0.8249 - val_loss: 0.0332 - val_accuracy: 0.8364\n","Epoch 163/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0342 - accuracy: 0.8259 - val_loss: 0.0331 - val_accuracy: 0.8373\n","Epoch 164/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0340 - accuracy: 0.8270 - val_loss: 0.0329 - val_accuracy: 0.8384\n","Epoch 165/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0338 - accuracy: 0.8278 - val_loss: 0.0327 - val_accuracy: 0.8393\n","Epoch 166/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0337 - accuracy: 0.8286 - val_loss: 0.0326 - val_accuracy: 0.8403\n","Epoch 167/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0335 - accuracy: 0.8298 - val_loss: 0.0324 - val_accuracy: 0.8411\n","Epoch 168/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0333 - accuracy: 0.8306 - val_loss: 0.0322 - val_accuracy: 0.8415\n","Epoch 169/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0332 - accuracy: 0.8315 - val_loss: 0.0321 - val_accuracy: 0.8420\n","Epoch 170/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0330 - accuracy: 0.8321 - val_loss: 0.0319 - val_accuracy: 0.8423\n","Epoch 171/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0329 - accuracy: 0.8331 - val_loss: 0.0317 - val_accuracy: 0.8429\n","Epoch 172/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0327 - accuracy: 0.8337 - val_loss: 0.0316 - val_accuracy: 0.8436\n","Epoch 173/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0325 - accuracy: 0.8345 - val_loss: 0.0314 - val_accuracy: 0.8441\n","Epoch 174/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0324 - accuracy: 0.8355 - val_loss: 0.0313 - val_accuracy: 0.8448\n","Epoch 175/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0322 - accuracy: 0.8364 - val_loss: 0.0311 - val_accuracy: 0.8461\n","Epoch 176/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0321 - accuracy: 0.8370 - val_loss: 0.0310 - val_accuracy: 0.8472\n","Epoch 177/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0320 - accuracy: 0.8377 - val_loss: 0.0308 - val_accuracy: 0.8481\n","Epoch 178/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0318 - accuracy: 0.8386 - val_loss: 0.0307 - val_accuracy: 0.8488\n","Epoch 179/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0317 - accuracy: 0.8391 - val_loss: 0.0306 - val_accuracy: 0.8492\n","Epoch 180/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0315 - accuracy: 0.8399 - val_loss: 0.0304 - val_accuracy: 0.8504\n","Epoch 181/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0314 - accuracy: 0.8407 - val_loss: 0.0303 - val_accuracy: 0.8510\n","Epoch 182/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0312 - accuracy: 0.8414 - val_loss: 0.0301 - val_accuracy: 0.8516\n","Epoch 183/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0311 - accuracy: 0.8419 - val_loss: 0.0300 - val_accuracy: 0.8516\n","Epoch 184/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0310 - accuracy: 0.8428 - val_loss: 0.0299 - val_accuracy: 0.8524\n","Epoch 185/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0308 - accuracy: 0.8433 - val_loss: 0.0297 - val_accuracy: 0.8528\n","Epoch 186/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.8441 - val_loss: 0.0296 - val_accuracy: 0.8535\n","Epoch 187/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.8446 - val_loss: 0.0295 - val_accuracy: 0.8536\n","Epoch 188/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0304 - accuracy: 0.8450 - val_loss: 0.0293 - val_accuracy: 0.8542\n","Epoch 189/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0303 - accuracy: 0.8456 - val_loss: 0.0292 - val_accuracy: 0.8548\n","Epoch 190/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0302 - accuracy: 0.8465 - val_loss: 0.0291 - val_accuracy: 0.8550\n","Epoch 191/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0301 - accuracy: 0.8468 - val_loss: 0.0290 - val_accuracy: 0.8560\n","Epoch 192/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0299 - accuracy: 0.8474 - val_loss: 0.0288 - val_accuracy: 0.8563\n","Epoch 193/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.8477 - val_loss: 0.0287 - val_accuracy: 0.8568\n","Epoch 194/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0297 - accuracy: 0.8483 - val_loss: 0.0286 - val_accuracy: 0.8574\n","Epoch 195/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0296 - accuracy: 0.8490 - val_loss: 0.0285 - val_accuracy: 0.8576\n","Epoch 196/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0295 - accuracy: 0.8495 - val_loss: 0.0284 - val_accuracy: 0.8581\n","Epoch 197/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0293 - accuracy: 0.8498 - val_loss: 0.0282 - val_accuracy: 0.8585\n","Epoch 198/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.8504 - val_loss: 0.0281 - val_accuracy: 0.8591\n","Epoch 199/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0291 - accuracy: 0.8510 - val_loss: 0.0280 - val_accuracy: 0.8594\n","Epoch 200/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0290 - accuracy: 0.8512 - val_loss: 0.0279 - val_accuracy: 0.8595\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ffa40319700>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["the model get accuracy at level of 85%. Now I'm gonna change learnig rate and see what will happen."],"metadata":{"id":"R2yl1Dt_T0-j"}},{"cell_type":"code","source":["model1 = Sequential()\n","model1.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n","model1.add(Dense(10, activation='softmax'))"],"metadata":{"id":"iN7zLJQ-UIp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])"],"metadata":{"id":"Nrkmko62UO32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hm6n6pgSUlnV","executionInfo":{"status":"ok","timestamp":1679069562420,"user_tz":-60,"elapsed":382627,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"565d1bc5-5390-40ad-b57c-9a85952718a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0903 - accuracy: 0.1745 - val_loss: 0.0882 - val_accuracy: 0.2457\n","Epoch 2/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0865 - accuracy: 0.3230 - val_loss: 0.0848 - val_accuracy: 0.3554\n","Epoch 3/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0829 - accuracy: 0.3721 - val_loss: 0.0809 - val_accuracy: 0.3936\n","Epoch 4/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0787 - accuracy: 0.4286 - val_loss: 0.0763 - val_accuracy: 0.4789\n","Epoch 5/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.5101 - val_loss: 0.0715 - val_accuracy: 0.5507\n","Epoch 6/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0691 - accuracy: 0.5701 - val_loss: 0.0666 - val_accuracy: 0.5941\n","Epoch 7/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0644 - accuracy: 0.6118 - val_loss: 0.0618 - val_accuracy: 0.6375\n","Epoch 8/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0598 - accuracy: 0.6538 - val_loss: 0.0574 - val_accuracy: 0.6781\n","Epoch 9/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.6898 - val_loss: 0.0533 - val_accuracy: 0.7098\n","Epoch 10/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0518 - accuracy: 0.7167 - val_loss: 0.0496 - val_accuracy: 0.7387\n","Epoch 11/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0483 - accuracy: 0.7379 - val_loss: 0.0463 - val_accuracy: 0.7528\n","Epoch 12/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0453 - accuracy: 0.7518 - val_loss: 0.0434 - val_accuracy: 0.7665\n","Epoch 13/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.7639 - val_loss: 0.0408 - val_accuracy: 0.7785\n","Epoch 14/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0401 - accuracy: 0.7763 - val_loss: 0.0384 - val_accuracy: 0.7944\n","Epoch 15/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0379 - accuracy: 0.7920 - val_loss: 0.0363 - val_accuracy: 0.8101\n","Epoch 16/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.8093 - val_loss: 0.0343 - val_accuracy: 0.8247\n","Epoch 17/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0341 - accuracy: 0.8224 - val_loss: 0.0326 - val_accuracy: 0.8373\n","Epoch 18/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0325 - accuracy: 0.8339 - val_loss: 0.0310 - val_accuracy: 0.8481\n","Epoch 19/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0310 - accuracy: 0.8425 - val_loss: 0.0296 - val_accuracy: 0.8563\n","Epoch 20/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0297 - accuracy: 0.8492 - val_loss: 0.0283 - val_accuracy: 0.8624\n","Epoch 21/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0285 - accuracy: 0.8554 - val_loss: 0.0271 - val_accuracy: 0.8661\n","Epoch 22/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0274 - accuracy: 0.8598 - val_loss: 0.0261 - val_accuracy: 0.8705\n","Epoch 23/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0264 - accuracy: 0.8640 - val_loss: 0.0252 - val_accuracy: 0.8744\n","Epoch 24/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0256 - accuracy: 0.8672 - val_loss: 0.0244 - val_accuracy: 0.8758\n","Epoch 25/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0248 - accuracy: 0.8701 - val_loss: 0.0236 - val_accuracy: 0.8783\n","Epoch 26/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0241 - accuracy: 0.8723 - val_loss: 0.0230 - val_accuracy: 0.8810\n","Epoch 27/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0235 - accuracy: 0.8747 - val_loss: 0.0224 - val_accuracy: 0.8834\n","Epoch 28/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0229 - accuracy: 0.8768 - val_loss: 0.0218 - val_accuracy: 0.8850\n","Epoch 29/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0224 - accuracy: 0.8782 - val_loss: 0.0213 - val_accuracy: 0.8872\n","Epoch 30/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0219 - accuracy: 0.8802 - val_loss: 0.0209 - val_accuracy: 0.8881\n","Epoch 31/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.8812 - val_loss: 0.0205 - val_accuracy: 0.8915\n","Epoch 32/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0211 - accuracy: 0.8824 - val_loss: 0.0201 - val_accuracy: 0.8929\n","Epoch 33/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.8837 - val_loss: 0.0197 - val_accuracy: 0.8937\n","Epoch 34/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.8849 - val_loss: 0.0194 - val_accuracy: 0.8942\n","Epoch 35/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0201 - accuracy: 0.8862 - val_loss: 0.0191 - val_accuracy: 0.8947\n","Epoch 36/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0198 - accuracy: 0.8873 - val_loss: 0.0188 - val_accuracy: 0.8963\n","Epoch 37/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0195 - accuracy: 0.8882 - val_loss: 0.0185 - val_accuracy: 0.8964\n","Epoch 38/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0192 - accuracy: 0.8893 - val_loss: 0.0183 - val_accuracy: 0.8971\n","Epoch 39/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0190 - accuracy: 0.8904 - val_loss: 0.0180 - val_accuracy: 0.8979\n","Epoch 40/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.8913 - val_loss: 0.0178 - val_accuracy: 0.8989\n","Epoch 41/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0186 - accuracy: 0.8924 - val_loss: 0.0176 - val_accuracy: 0.8997\n","Epoch 42/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0183 - accuracy: 0.8930 - val_loss: 0.0174 - val_accuracy: 0.9001\n","Epoch 43/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0182 - accuracy: 0.8940 - val_loss: 0.0172 - val_accuracy: 0.9009\n","Epoch 44/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.8947 - val_loss: 0.0170 - val_accuracy: 0.9009\n","Epoch 45/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0178 - accuracy: 0.8953 - val_loss: 0.0169 - val_accuracy: 0.9011\n","Epoch 46/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0176 - accuracy: 0.8960 - val_loss: 0.0167 - val_accuracy: 0.9020\n","Epoch 47/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0175 - accuracy: 0.8966 - val_loss: 0.0166 - val_accuracy: 0.9029\n","Epoch 48/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0173 - accuracy: 0.8972 - val_loss: 0.0164 - val_accuracy: 0.9032\n","Epoch 49/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0172 - accuracy: 0.8978 - val_loss: 0.0163 - val_accuracy: 0.9035\n","Epoch 50/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0170 - accuracy: 0.8982 - val_loss: 0.0161 - val_accuracy: 0.9042\n","Epoch 51/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0169 - accuracy: 0.8990 - val_loss: 0.0160 - val_accuracy: 0.9055\n","Epoch 52/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0168 - accuracy: 0.8996 - val_loss: 0.0159 - val_accuracy: 0.9062\n","Epoch 53/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0166 - accuracy: 0.9001 - val_loss: 0.0158 - val_accuracy: 0.9069\n","Epoch 54/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0165 - accuracy: 0.9007 - val_loss: 0.0157 - val_accuracy: 0.9064\n","Epoch 55/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0164 - accuracy: 0.9012 - val_loss: 0.0156 - val_accuracy: 0.9076\n","Epoch 56/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0163 - accuracy: 0.9017 - val_loss: 0.0154 - val_accuracy: 0.9082\n","Epoch 57/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9022 - val_loss: 0.0153 - val_accuracy: 0.9087\n","Epoch 58/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0161 - accuracy: 0.9027 - val_loss: 0.0152 - val_accuracy: 0.9091\n","Epoch 59/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0160 - accuracy: 0.9033 - val_loss: 0.0152 - val_accuracy: 0.9096\n","Epoch 60/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9036 - val_loss: 0.0151 - val_accuracy: 0.9095\n","Epoch 61/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0158 - accuracy: 0.9041 - val_loss: 0.0150 - val_accuracy: 0.9093\n","Epoch 62/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9045 - val_loss: 0.0149 - val_accuracy: 0.9102\n","Epoch 63/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0156 - accuracy: 0.9047 - val_loss: 0.0148 - val_accuracy: 0.9103\n","Epoch 64/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0155 - accuracy: 0.9053 - val_loss: 0.0147 - val_accuracy: 0.9105\n","Epoch 65/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0154 - accuracy: 0.9056 - val_loss: 0.0146 - val_accuracy: 0.9110\n","Epoch 66/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0153 - accuracy: 0.9059 - val_loss: 0.0146 - val_accuracy: 0.9115\n","Epoch 67/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0153 - accuracy: 0.9065 - val_loss: 0.0145 - val_accuracy: 0.9118\n","Epoch 68/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0152 - accuracy: 0.9069 - val_loss: 0.0144 - val_accuracy: 0.9125\n","Epoch 69/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0151 - accuracy: 0.9073 - val_loss: 0.0143 - val_accuracy: 0.9130\n","Epoch 70/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9076 - val_loss: 0.0143 - val_accuracy: 0.9132\n","Epoch 71/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0150 - accuracy: 0.9079 - val_loss: 0.0142 - val_accuracy: 0.9137\n","Epoch 72/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0149 - accuracy: 0.9086 - val_loss: 0.0141 - val_accuracy: 0.9139\n","Epoch 73/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0148 - accuracy: 0.9087 - val_loss: 0.0141 - val_accuracy: 0.9145\n","Epoch 74/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0147 - accuracy: 0.9092 - val_loss: 0.0140 - val_accuracy: 0.9147\n","Epoch 75/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0147 - accuracy: 0.9094 - val_loss: 0.0140 - val_accuracy: 0.9148\n","Epoch 76/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0146 - accuracy: 0.9097 - val_loss: 0.0139 - val_accuracy: 0.9149\n","Epoch 77/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0146 - accuracy: 0.9099 - val_loss: 0.0138 - val_accuracy: 0.9152\n","Epoch 78/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0145 - accuracy: 0.9104 - val_loss: 0.0138 - val_accuracy: 0.9155\n","Epoch 79/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0144 - accuracy: 0.9108 - val_loss: 0.0137 - val_accuracy: 0.9151\n","Epoch 80/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0144 - accuracy: 0.9109 - val_loss: 0.0137 - val_accuracy: 0.9160\n","Epoch 81/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0143 - accuracy: 0.9113 - val_loss: 0.0136 - val_accuracy: 0.9164\n","Epoch 82/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9116 - val_loss: 0.0136 - val_accuracy: 0.9163\n","Epoch 83/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0142 - accuracy: 0.9118 - val_loss: 0.0135 - val_accuracy: 0.9173\n","Epoch 84/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0141 - accuracy: 0.9118 - val_loss: 0.0135 - val_accuracy: 0.9170\n","Epoch 85/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0141 - accuracy: 0.9123 - val_loss: 0.0134 - val_accuracy: 0.9175\n","Epoch 86/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0140 - accuracy: 0.9128 - val_loss: 0.0134 - val_accuracy: 0.9177\n","Epoch 87/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0140 - accuracy: 0.9133 - val_loss: 0.0133 - val_accuracy: 0.9181\n","Epoch 88/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9132 - val_loss: 0.0133 - val_accuracy: 0.9182\n","Epoch 89/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0139 - accuracy: 0.9135 - val_loss: 0.0132 - val_accuracy: 0.9187\n","Epoch 90/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9138 - val_loss: 0.0132 - val_accuracy: 0.9187\n","Epoch 91/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9141 - val_loss: 0.0131 - val_accuracy: 0.9191\n","Epoch 92/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9144 - val_loss: 0.0131 - val_accuracy: 0.9191\n","Epoch 93/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9146 - val_loss: 0.0131 - val_accuracy: 0.9200\n","Epoch 94/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9147 - val_loss: 0.0130 - val_accuracy: 0.9203\n","Epoch 95/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0136 - accuracy: 0.9150 - val_loss: 0.0130 - val_accuracy: 0.9202\n","Epoch 96/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9154 - val_loss: 0.0129 - val_accuracy: 0.9209\n","Epoch 97/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9156 - val_loss: 0.0129 - val_accuracy: 0.9214\n","Epoch 98/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9158 - val_loss: 0.0129 - val_accuracy: 0.9212\n","Epoch 99/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0134 - accuracy: 0.9158 - val_loss: 0.0128 - val_accuracy: 0.9209\n","Epoch 100/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0134 - accuracy: 0.9163 - val_loss: 0.0128 - val_accuracy: 0.9216\n","Epoch 101/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9163 - val_loss: 0.0127 - val_accuracy: 0.9219\n","Epoch 102/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0133 - accuracy: 0.9166 - val_loss: 0.0127 - val_accuracy: 0.9220\n","Epoch 103/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9170 - val_loss: 0.0127 - val_accuracy: 0.9225\n","Epoch 104/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9171 - val_loss: 0.0126 - val_accuracy: 0.9224\n","Epoch 105/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9173 - val_loss: 0.0126 - val_accuracy: 0.9228\n","Epoch 106/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0131 - accuracy: 0.9179 - val_loss: 0.0126 - val_accuracy: 0.9230\n","Epoch 107/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9178 - val_loss: 0.0125 - val_accuracy: 0.9231\n","Epoch 108/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.9182 - val_loss: 0.0125 - val_accuracy: 0.9235\n","Epoch 109/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0130 - accuracy: 0.9186 - val_loss: 0.0125 - val_accuracy: 0.9231\n","Epoch 110/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0130 - accuracy: 0.9189 - val_loss: 0.0124 - val_accuracy: 0.9227\n","Epoch 111/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0129 - accuracy: 0.9191 - val_loss: 0.0124 - val_accuracy: 0.9236\n","Epoch 112/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0129 - accuracy: 0.9192 - val_loss: 0.0124 - val_accuracy: 0.9231\n","Epoch 113/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0129 - accuracy: 0.9196 - val_loss: 0.0123 - val_accuracy: 0.9236\n","Epoch 114/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.9196 - val_loss: 0.0123 - val_accuracy: 0.9241\n","Epoch 115/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0128 - accuracy: 0.9200 - val_loss: 0.0123 - val_accuracy: 0.9239\n","Epoch 116/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.9203 - val_loss: 0.0122 - val_accuracy: 0.9242\n","Epoch 117/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9204 - val_loss: 0.0122 - val_accuracy: 0.9247\n","Epoch 118/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9206 - val_loss: 0.0122 - val_accuracy: 0.9248\n","Epoch 119/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0127 - accuracy: 0.9208 - val_loss: 0.0122 - val_accuracy: 0.9251\n","Epoch 120/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0126 - accuracy: 0.9208 - val_loss: 0.0121 - val_accuracy: 0.9254\n","Epoch 121/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0126 - accuracy: 0.9210 - val_loss: 0.0121 - val_accuracy: 0.9255\n","Epoch 122/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0126 - accuracy: 0.9213 - val_loss: 0.0121 - val_accuracy: 0.9256\n","Epoch 123/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9214 - val_loss: 0.0120 - val_accuracy: 0.9257\n","Epoch 124/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9219 - val_loss: 0.0120 - val_accuracy: 0.9258\n","Epoch 125/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9219 - val_loss: 0.0120 - val_accuracy: 0.9260\n","Epoch 126/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.9219 - val_loss: 0.0120 - val_accuracy: 0.9261\n","Epoch 127/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.9222 - val_loss: 0.0119 - val_accuracy: 0.9260\n","Epoch 128/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0124 - accuracy: 0.9224 - val_loss: 0.0119 - val_accuracy: 0.9260\n","Epoch 129/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0123 - accuracy: 0.9227 - val_loss: 0.0119 - val_accuracy: 0.9261\n","Epoch 130/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9228 - val_loss: 0.0119 - val_accuracy: 0.9266\n","Epoch 131/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0123 - accuracy: 0.9229 - val_loss: 0.0118 - val_accuracy: 0.9263\n","Epoch 132/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0122 - accuracy: 0.9230 - val_loss: 0.0118 - val_accuracy: 0.9268\n","Epoch 133/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0122 - accuracy: 0.9231 - val_loss: 0.0118 - val_accuracy: 0.9271\n","Epoch 134/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0122 - accuracy: 0.9234 - val_loss: 0.0118 - val_accuracy: 0.9265\n","Epoch 135/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0122 - accuracy: 0.9237 - val_loss: 0.0117 - val_accuracy: 0.9270\n","Epoch 136/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0121 - accuracy: 0.9237 - val_loss: 0.0117 - val_accuracy: 0.9275\n","Epoch 137/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9240 - val_loss: 0.0117 - val_accuracy: 0.9274\n","Epoch 138/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9240 - val_loss: 0.0117 - val_accuracy: 0.9272\n","Epoch 139/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0120 - accuracy: 0.9242 - val_loss: 0.0116 - val_accuracy: 0.9276\n","Epoch 140/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0120 - accuracy: 0.9245 - val_loss: 0.0116 - val_accuracy: 0.9273\n","Epoch 141/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0120 - accuracy: 0.9244 - val_loss: 0.0116 - val_accuracy: 0.9280\n","Epoch 142/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0120 - accuracy: 0.9247 - val_loss: 0.0116 - val_accuracy: 0.9273\n","Epoch 143/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0119 - accuracy: 0.9248 - val_loss: 0.0115 - val_accuracy: 0.9272\n","Epoch 144/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0119 - accuracy: 0.9250 - val_loss: 0.0115 - val_accuracy: 0.9279\n","Epoch 145/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0119 - accuracy: 0.9251 - val_loss: 0.0115 - val_accuracy: 0.9279\n","Epoch 146/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0119 - accuracy: 0.9255 - val_loss: 0.0115 - val_accuracy: 0.9275\n","Epoch 147/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0118 - accuracy: 0.9255 - val_loss: 0.0115 - val_accuracy: 0.9276\n","Epoch 148/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0118 - accuracy: 0.9257 - val_loss: 0.0114 - val_accuracy: 0.9278\n","Epoch 149/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0118 - accuracy: 0.9257 - val_loss: 0.0114 - val_accuracy: 0.9276\n","Epoch 150/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0118 - accuracy: 0.9258 - val_loss: 0.0114 - val_accuracy: 0.9279\n","Epoch 151/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.9259 - val_loss: 0.0114 - val_accuracy: 0.9280\n","Epoch 152/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.9262 - val_loss: 0.0114 - val_accuracy: 0.9278\n","Epoch 153/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.9264 - val_loss: 0.0113 - val_accuracy: 0.9278\n","Epoch 154/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0117 - accuracy: 0.9266 - val_loss: 0.0113 - val_accuracy: 0.9278\n","Epoch 155/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9267 - val_loss: 0.0113 - val_accuracy: 0.9278\n","Epoch 156/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9267 - val_loss: 0.0113 - val_accuracy: 0.9281\n","Epoch 157/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9267 - val_loss: 0.0112 - val_accuracy: 0.9280\n","Epoch 158/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9271 - val_loss: 0.0112 - val_accuracy: 0.9282\n","Epoch 159/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0115 - accuracy: 0.9274 - val_loss: 0.0112 - val_accuracy: 0.9284\n","Epoch 160/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0115 - accuracy: 0.9274 - val_loss: 0.0112 - val_accuracy: 0.9283\n","Epoch 161/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0115 - accuracy: 0.9275 - val_loss: 0.0112 - val_accuracy: 0.9285\n","Epoch 162/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9277 - val_loss: 0.0112 - val_accuracy: 0.9287\n","Epoch 163/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0114 - accuracy: 0.9277 - val_loss: 0.0111 - val_accuracy: 0.9291\n","Epoch 164/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0114 - accuracy: 0.9279 - val_loss: 0.0111 - val_accuracy: 0.9288\n","Epoch 165/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0114 - accuracy: 0.9281 - val_loss: 0.0111 - val_accuracy: 0.9288\n","Epoch 166/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0114 - accuracy: 0.9282 - val_loss: 0.0111 - val_accuracy: 0.9290\n","Epoch 167/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0113 - accuracy: 0.9283 - val_loss: 0.0111 - val_accuracy: 0.9293\n","Epoch 168/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0113 - accuracy: 0.9285 - val_loss: 0.0110 - val_accuracy: 0.9294\n","Epoch 169/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9285 - val_loss: 0.0110 - val_accuracy: 0.9296\n","Epoch 170/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0113 - accuracy: 0.9287 - val_loss: 0.0110 - val_accuracy: 0.9298\n","Epoch 171/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9289 - val_loss: 0.0110 - val_accuracy: 0.9296\n","Epoch 172/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0112 - accuracy: 0.9290 - val_loss: 0.0110 - val_accuracy: 0.9298\n","Epoch 173/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0112 - accuracy: 0.9292 - val_loss: 0.0109 - val_accuracy: 0.9298\n","Epoch 174/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.9293 - val_loss: 0.0109 - val_accuracy: 0.9300\n","Epoch 175/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.9296 - val_loss: 0.0109 - val_accuracy: 0.9304\n","Epoch 176/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0112 - accuracy: 0.9297 - val_loss: 0.0109 - val_accuracy: 0.9307\n","Epoch 177/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0111 - accuracy: 0.9298 - val_loss: 0.0109 - val_accuracy: 0.9308\n","Epoch 178/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9299 - val_loss: 0.0109 - val_accuracy: 0.9306\n","Epoch 179/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9301 - val_loss: 0.0108 - val_accuracy: 0.9310\n","Epoch 180/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9301 - val_loss: 0.0108 - val_accuracy: 0.9310\n","Epoch 181/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9302 - val_loss: 0.0108 - val_accuracy: 0.9306\n","Epoch 182/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9304 - val_loss: 0.0108 - val_accuracy: 0.9313\n","Epoch 183/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0110 - accuracy: 0.9306 - val_loss: 0.0108 - val_accuracy: 0.9309\n","Epoch 184/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9306 - val_loss: 0.0108 - val_accuracy: 0.9312\n","Epoch 185/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9307 - val_loss: 0.0107 - val_accuracy: 0.9314\n","Epoch 186/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0109 - accuracy: 0.9308 - val_loss: 0.0107 - val_accuracy: 0.9320\n","Epoch 187/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.9309 - val_loss: 0.0107 - val_accuracy: 0.9318\n","Epoch 188/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.9310 - val_loss: 0.0107 - val_accuracy: 0.9318\n","Epoch 189/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0109 - accuracy: 0.9313 - val_loss: 0.0107 - val_accuracy: 0.9323\n","Epoch 190/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.9314 - val_loss: 0.0107 - val_accuracy: 0.9319\n","Epoch 191/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0108 - accuracy: 0.9316 - val_loss: 0.0106 - val_accuracy: 0.9322\n","Epoch 192/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.9317 - val_loss: 0.0106 - val_accuracy: 0.9323\n","Epoch 193/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0108 - accuracy: 0.9319 - val_loss: 0.0106 - val_accuracy: 0.9325\n","Epoch 194/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0108 - accuracy: 0.9319 - val_loss: 0.0106 - val_accuracy: 0.9324\n","Epoch 195/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0108 - accuracy: 0.9321 - val_loss: 0.0106 - val_accuracy: 0.9327\n","Epoch 196/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0107 - accuracy: 0.9323 - val_loss: 0.0106 - val_accuracy: 0.9330\n","Epoch 197/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9323 - val_loss: 0.0105 - val_accuracy: 0.9326\n","Epoch 198/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9325 - val_loss: 0.0105 - val_accuracy: 0.9327\n","Epoch 199/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9328 - val_loss: 0.0105 - val_accuracy: 0.9326\n","Epoch 200/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9327 - val_loss: 0.0105 - val_accuracy: 0.9329\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ffa2c0306d0>"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["Now the model got accuracy at level of 93%, but the fact worth noticing is that it got the better acuuracy than previous model on more or less 40th epoch. I will now play with another parameters and compare it to basic model (in my case - just named model)"],"metadata":{"id":"irYRkfmIWFJh"}},{"cell_type":"code","source":["model2 = Sequential()\n","model2.add(Dense(32, activation='sigmoid', input_shape=(784,)))\n","model2.add(Dense(10, activation='softmax'))"],"metadata":{"id":"drD55UnAWa2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"],"metadata":{"id":"60rhaye7Wg7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8vtSRPiXIh4","executionInfo":{"status":"ok","timestamp":1679070183845,"user_tz":-60,"elapsed":335617,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"061ba8de-abbd-4f9c-f6d9-6c496ca8d319"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0933 - accuracy: 0.0885 - val_loss: 0.0928 - val_accuracy: 0.0912\n","Epoch 2/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.0918 - val_loss: 0.0921 - val_accuracy: 0.0988\n","Epoch 3/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.1007 - val_loss: 0.0916 - val_accuracy: 0.1091\n","Epoch 4/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0915 - accuracy: 0.1123 - val_loss: 0.0912 - val_accuracy: 0.1240\n","Epoch 5/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.1273 - val_loss: 0.0908 - val_accuracy: 0.1411\n","Epoch 6/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0908 - accuracy: 0.1461 - val_loss: 0.0904 - val_accuracy: 0.1615\n","Epoch 7/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0904 - accuracy: 0.1682 - val_loss: 0.0901 - val_accuracy: 0.1888\n","Epoch 8/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.1932 - val_loss: 0.0898 - val_accuracy: 0.2157\n","Epoch 9/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.2199 - val_loss: 0.0896 - val_accuracy: 0.2445\n","Epoch 10/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.2494 - val_loss: 0.0893 - val_accuracy: 0.2736\n","Epoch 11/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0893 - accuracy: 0.2745 - val_loss: 0.0890 - val_accuracy: 0.2982\n","Epoch 12/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.2950 - val_loss: 0.0888 - val_accuracy: 0.3167\n","Epoch 13/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.3138 - val_loss: 0.0885 - val_accuracy: 0.3297\n","Epoch 14/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0885 - accuracy: 0.3263 - val_loss: 0.0882 - val_accuracy: 0.3379\n","Epoch 15/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0883 - accuracy: 0.3354 - val_loss: 0.0880 - val_accuracy: 0.3419\n","Epoch 16/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0880 - accuracy: 0.3397 - val_loss: 0.0877 - val_accuracy: 0.3463\n","Epoch 17/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.3434 - val_loss: 0.0874 - val_accuracy: 0.3502\n","Epoch 18/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.3457 - val_loss: 0.0872 - val_accuracy: 0.3525\n","Epoch 19/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0872 - accuracy: 0.3465 - val_loss: 0.0869 - val_accuracy: 0.3535\n","Epoch 20/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0870 - accuracy: 0.3466 - val_loss: 0.0866 - val_accuracy: 0.3538\n","Epoch 21/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0867 - accuracy: 0.3463 - val_loss: 0.0864 - val_accuracy: 0.3535\n","Epoch 22/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0864 - accuracy: 0.3460 - val_loss: 0.0861 - val_accuracy: 0.3526\n","Epoch 23/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0861 - accuracy: 0.3452 - val_loss: 0.0858 - val_accuracy: 0.3518\n","Epoch 24/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0859 - accuracy: 0.3444 - val_loss: 0.0855 - val_accuracy: 0.3522\n","Epoch 25/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0856 - accuracy: 0.3436 - val_loss: 0.0852 - val_accuracy: 0.3518\n","Epoch 26/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.3430 - val_loss: 0.0849 - val_accuracy: 0.3513\n","Epoch 27/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0850 - accuracy: 0.3426 - val_loss: 0.0846 - val_accuracy: 0.3509\n","Epoch 28/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.3424 - val_loss: 0.0843 - val_accuracy: 0.3509\n","Epoch 29/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.3429 - val_loss: 0.0839 - val_accuracy: 0.3517\n","Epoch 30/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.3429 - val_loss: 0.0836 - val_accuracy: 0.3514\n","Epoch 31/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0837 - accuracy: 0.3432 - val_loss: 0.0833 - val_accuracy: 0.3516\n","Epoch 32/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0834 - accuracy: 0.3438 - val_loss: 0.0829 - val_accuracy: 0.3529\n","Epoch 33/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.3440 - val_loss: 0.0826 - val_accuracy: 0.3537\n","Epoch 34/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.3459 - val_loss: 0.0823 - val_accuracy: 0.3555\n","Epoch 35/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.3478 - val_loss: 0.0819 - val_accuracy: 0.3573\n","Epoch 36/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.3505 - val_loss: 0.0816 - val_accuracy: 0.3608\n","Epoch 37/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0817 - accuracy: 0.3533 - val_loss: 0.0812 - val_accuracy: 0.3649\n","Epoch 38/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.3568 - val_loss: 0.0808 - val_accuracy: 0.3693\n","Epoch 39/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.3614 - val_loss: 0.0805 - val_accuracy: 0.3740\n","Epoch 40/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.3650 - val_loss: 0.0801 - val_accuracy: 0.3802\n","Epoch 41/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0803 - accuracy: 0.3705 - val_loss: 0.0798 - val_accuracy: 0.3846\n","Epoch 42/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0799 - accuracy: 0.3752 - val_loss: 0.0794 - val_accuracy: 0.3892\n","Epoch 43/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0795 - accuracy: 0.3807 - val_loss: 0.0790 - val_accuracy: 0.3950\n","Epoch 44/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0792 - accuracy: 0.3866 - val_loss: 0.0786 - val_accuracy: 0.4002\n","Epoch 45/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 0.3919 - val_loss: 0.0783 - val_accuracy: 0.4046\n","Epoch 46/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.3975 - val_loss: 0.0779 - val_accuracy: 0.4099\n","Epoch 47/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0781 - accuracy: 0.4037 - val_loss: 0.0775 - val_accuracy: 0.4154\n","Epoch 48/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.4096 - val_loss: 0.0772 - val_accuracy: 0.4226\n","Epoch 49/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.4160 - val_loss: 0.0768 - val_accuracy: 0.4287\n","Epoch 50/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.4221 - val_loss: 0.0764 - val_accuracy: 0.4330\n","Epoch 51/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.4285 - val_loss: 0.0760 - val_accuracy: 0.4396\n","Epoch 52/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0763 - accuracy: 0.4342 - val_loss: 0.0757 - val_accuracy: 0.4448\n","Epoch 53/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.4404 - val_loss: 0.0753 - val_accuracy: 0.4501\n","Epoch 54/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0755 - accuracy: 0.4465 - val_loss: 0.0749 - val_accuracy: 0.4560\n","Epoch 55/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0752 - accuracy: 0.4523 - val_loss: 0.0746 - val_accuracy: 0.4617\n","Epoch 56/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0748 - accuracy: 0.4572 - val_loss: 0.0742 - val_accuracy: 0.4663\n","Epoch 57/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.4634 - val_loss: 0.0739 - val_accuracy: 0.4715\n","Epoch 58/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0741 - accuracy: 0.4690 - val_loss: 0.0735 - val_accuracy: 0.4777\n","Epoch 59/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.4748 - val_loss: 0.0732 - val_accuracy: 0.4827\n","Epoch 60/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0734 - accuracy: 0.4811 - val_loss: 0.0728 - val_accuracy: 0.4884\n","Epoch 61/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.4874 - val_loss: 0.0724 - val_accuracy: 0.4955\n","Epoch 62/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0727 - accuracy: 0.4931 - val_loss: 0.0721 - val_accuracy: 0.5004\n","Epoch 63/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0724 - accuracy: 0.4987 - val_loss: 0.0718 - val_accuracy: 0.5049\n","Epoch 64/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.5046 - val_loss: 0.0714 - val_accuracy: 0.5099\n","Epoch 65/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0717 - accuracy: 0.5100 - val_loss: 0.0711 - val_accuracy: 0.5141\n","Epoch 66/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0713 - accuracy: 0.5153 - val_loss: 0.0707 - val_accuracy: 0.5193\n","Epoch 67/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.5210 - val_loss: 0.0704 - val_accuracy: 0.5244\n","Epoch 68/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.5265 - val_loss: 0.0700 - val_accuracy: 0.5296\n","Epoch 69/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.5312 - val_loss: 0.0697 - val_accuracy: 0.5355\n","Epoch 70/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.5358 - val_loss: 0.0694 - val_accuracy: 0.5395\n","Epoch 71/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0697 - accuracy: 0.5409 - val_loss: 0.0690 - val_accuracy: 0.5432\n","Epoch 72/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0693 - accuracy: 0.5457 - val_loss: 0.0687 - val_accuracy: 0.5479\n","Epoch 73/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.5505 - val_loss: 0.0684 - val_accuracy: 0.5524\n","Epoch 74/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0687 - accuracy: 0.5549 - val_loss: 0.0680 - val_accuracy: 0.5568\n","Epoch 75/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0683 - accuracy: 0.5587 - val_loss: 0.0677 - val_accuracy: 0.5594\n","Epoch 76/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.5625 - val_loss: 0.0674 - val_accuracy: 0.5628\n","Epoch 77/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.5670 - val_loss: 0.0670 - val_accuracy: 0.5672\n","Epoch 78/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0674 - accuracy: 0.5707 - val_loss: 0.0667 - val_accuracy: 0.5712\n","Epoch 79/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0670 - accuracy: 0.5744 - val_loss: 0.0664 - val_accuracy: 0.5741\n","Epoch 80/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0667 - accuracy: 0.5778 - val_loss: 0.0661 - val_accuracy: 0.5770\n","Epoch 81/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.5814 - val_loss: 0.0657 - val_accuracy: 0.5804\n","Epoch 82/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.5853 - val_loss: 0.0654 - val_accuracy: 0.5821\n","Epoch 83/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0657 - accuracy: 0.5879 - val_loss: 0.0651 - val_accuracy: 0.5861\n","Epoch 84/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0654 - accuracy: 0.5913 - val_loss: 0.0648 - val_accuracy: 0.5891\n","Epoch 85/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0651 - accuracy: 0.5939 - val_loss: 0.0644 - val_accuracy: 0.5919\n","Epoch 86/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0648 - accuracy: 0.5971 - val_loss: 0.0641 - val_accuracy: 0.5954\n","Epoch 87/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0645 - accuracy: 0.6003 - val_loss: 0.0638 - val_accuracy: 0.5983\n","Epoch 88/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.6025 - val_loss: 0.0635 - val_accuracy: 0.6019\n","Epoch 89/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0638 - accuracy: 0.6057 - val_loss: 0.0632 - val_accuracy: 0.6051\n","Epoch 90/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0635 - accuracy: 0.6089 - val_loss: 0.0628 - val_accuracy: 0.6090\n","Epoch 91/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0632 - accuracy: 0.6121 - val_loss: 0.0625 - val_accuracy: 0.6123\n","Epoch 92/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0629 - accuracy: 0.6151 - val_loss: 0.0622 - val_accuracy: 0.6148\n","Epoch 93/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0626 - accuracy: 0.6180 - val_loss: 0.0619 - val_accuracy: 0.6173\n","Epoch 94/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0622 - accuracy: 0.6205 - val_loss: 0.0616 - val_accuracy: 0.6195\n","Epoch 95/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0619 - accuracy: 0.6229 - val_loss: 0.0613 - val_accuracy: 0.6222\n","Epoch 96/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0616 - accuracy: 0.6255 - val_loss: 0.0609 - val_accuracy: 0.6257\n","Epoch 97/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0613 - accuracy: 0.6282 - val_loss: 0.0606 - val_accuracy: 0.6283\n","Epoch 98/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0610 - accuracy: 0.6309 - val_loss: 0.0603 - val_accuracy: 0.6321\n","Epoch 99/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.6341 - val_loss: 0.0600 - val_accuracy: 0.6351\n","Epoch 100/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.6366 - val_loss: 0.0597 - val_accuracy: 0.6387\n","Epoch 101/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0601 - accuracy: 0.6387 - val_loss: 0.0594 - val_accuracy: 0.6410\n","Epoch 102/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.6410 - val_loss: 0.0591 - val_accuracy: 0.6430\n","Epoch 103/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0594 - accuracy: 0.6432 - val_loss: 0.0588 - val_accuracy: 0.6453\n","Epoch 104/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.6457 - val_loss: 0.0584 - val_accuracy: 0.6479\n","Epoch 105/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.6481 - val_loss: 0.0581 - val_accuracy: 0.6503\n","Epoch 106/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0585 - accuracy: 0.6502 - val_loss: 0.0578 - val_accuracy: 0.6533\n","Epoch 107/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.6525 - val_loss: 0.0575 - val_accuracy: 0.6552\n","Epoch 108/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0579 - accuracy: 0.6548 - val_loss: 0.0572 - val_accuracy: 0.6578\n","Epoch 109/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0576 - accuracy: 0.6572 - val_loss: 0.0569 - val_accuracy: 0.6603\n","Epoch 110/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0573 - accuracy: 0.6590 - val_loss: 0.0566 - val_accuracy: 0.6620\n","Epoch 111/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0570 - accuracy: 0.6610 - val_loss: 0.0563 - val_accuracy: 0.6643\n","Epoch 112/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0567 - accuracy: 0.6628 - val_loss: 0.0560 - val_accuracy: 0.6656\n","Epoch 113/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.6645 - val_loss: 0.0557 - val_accuracy: 0.6683\n","Epoch 114/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0561 - accuracy: 0.6668 - val_loss: 0.0554 - val_accuracy: 0.6712\n","Epoch 115/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0558 - accuracy: 0.6689 - val_loss: 0.0551 - val_accuracy: 0.6730\n","Epoch 116/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0555 - accuracy: 0.6711 - val_loss: 0.0548 - val_accuracy: 0.6743\n","Epoch 117/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0552 - accuracy: 0.6726 - val_loss: 0.0545 - val_accuracy: 0.6767\n","Epoch 118/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.6743 - val_loss: 0.0542 - val_accuracy: 0.6788\n","Epoch 119/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0546 - accuracy: 0.6762 - val_loss: 0.0539 - val_accuracy: 0.6806\n","Epoch 120/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.6781 - val_loss: 0.0536 - val_accuracy: 0.6831\n","Epoch 121/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.6799 - val_loss: 0.0533 - val_accuracy: 0.6848\n","Epoch 122/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0537 - accuracy: 0.6814 - val_loss: 0.0530 - val_accuracy: 0.6865\n","Epoch 123/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0534 - accuracy: 0.6831 - val_loss: 0.0527 - val_accuracy: 0.6891\n","Epoch 124/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0532 - accuracy: 0.6847 - val_loss: 0.0524 - val_accuracy: 0.6913\n","Epoch 125/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0529 - accuracy: 0.6864 - val_loss: 0.0522 - val_accuracy: 0.6937\n","Epoch 126/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0526 - accuracy: 0.6878 - val_loss: 0.0519 - val_accuracy: 0.6956\n","Epoch 127/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0523 - accuracy: 0.6897 - val_loss: 0.0516 - val_accuracy: 0.6979\n","Epoch 128/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0520 - accuracy: 0.6914 - val_loss: 0.0513 - val_accuracy: 0.7000\n","Epoch 129/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0517 - accuracy: 0.6932 - val_loss: 0.0510 - val_accuracy: 0.7018\n","Epoch 130/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0515 - accuracy: 0.6951 - val_loss: 0.0507 - val_accuracy: 0.7033\n","Epoch 131/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0512 - accuracy: 0.6968 - val_loss: 0.0504 - val_accuracy: 0.7059\n","Epoch 132/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0509 - accuracy: 0.6988 - val_loss: 0.0502 - val_accuracy: 0.7076\n","Epoch 133/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.7005 - val_loss: 0.0499 - val_accuracy: 0.7093\n","Epoch 134/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0504 - accuracy: 0.7026 - val_loss: 0.0496 - val_accuracy: 0.7110\n","Epoch 135/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0501 - accuracy: 0.7047 - val_loss: 0.0493 - val_accuracy: 0.7132\n","Epoch 136/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.7064 - val_loss: 0.0491 - val_accuracy: 0.7154\n","Epoch 137/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0495 - accuracy: 0.7082 - val_loss: 0.0488 - val_accuracy: 0.7183\n","Epoch 138/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0493 - accuracy: 0.7101 - val_loss: 0.0485 - val_accuracy: 0.7202\n","Epoch 139/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0490 - accuracy: 0.7118 - val_loss: 0.0483 - val_accuracy: 0.7221\n","Epoch 140/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0488 - accuracy: 0.7138 - val_loss: 0.0480 - val_accuracy: 0.7238\n","Epoch 141/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0485 - accuracy: 0.7154 - val_loss: 0.0477 - val_accuracy: 0.7254\n","Epoch 142/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0482 - accuracy: 0.7176 - val_loss: 0.0475 - val_accuracy: 0.7272\n","Epoch 143/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.7199 - val_loss: 0.0472 - val_accuracy: 0.7298\n","Epoch 144/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.7216 - val_loss: 0.0470 - val_accuracy: 0.7323\n","Epoch 145/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0475 - accuracy: 0.7234 - val_loss: 0.0467 - val_accuracy: 0.7345\n","Epoch 146/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0472 - accuracy: 0.7255 - val_loss: 0.0464 - val_accuracy: 0.7362\n","Epoch 147/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0470 - accuracy: 0.7275 - val_loss: 0.0462 - val_accuracy: 0.7387\n","Epoch 148/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0467 - accuracy: 0.7296 - val_loss: 0.0459 - val_accuracy: 0.7410\n","Epoch 149/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0465 - accuracy: 0.7318 - val_loss: 0.0457 - val_accuracy: 0.7435\n","Epoch 150/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0462 - accuracy: 0.7342 - val_loss: 0.0454 - val_accuracy: 0.7449\n","Epoch 151/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0460 - accuracy: 0.7361 - val_loss: 0.0452 - val_accuracy: 0.7475\n","Epoch 152/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0457 - accuracy: 0.7382 - val_loss: 0.0449 - val_accuracy: 0.7503\n","Epoch 153/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0455 - accuracy: 0.7404 - val_loss: 0.0447 - val_accuracy: 0.7525\n","Epoch 154/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0452 - accuracy: 0.7428 - val_loss: 0.0444 - val_accuracy: 0.7543\n","Epoch 155/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.7448 - val_loss: 0.0442 - val_accuracy: 0.7568\n","Epoch 156/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0448 - accuracy: 0.7470 - val_loss: 0.0440 - val_accuracy: 0.7582\n","Epoch 157/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.7493 - val_loss: 0.0437 - val_accuracy: 0.7609\n","Epoch 158/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0443 - accuracy: 0.7513 - val_loss: 0.0435 - val_accuracy: 0.7630\n","Epoch 159/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0441 - accuracy: 0.7536 - val_loss: 0.0433 - val_accuracy: 0.7649\n","Epoch 160/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0438 - accuracy: 0.7556 - val_loss: 0.0430 - val_accuracy: 0.7677\n","Epoch 161/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0436 - accuracy: 0.7579 - val_loss: 0.0428 - val_accuracy: 0.7696\n","Epoch 162/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.7601 - val_loss: 0.0426 - val_accuracy: 0.7715\n","Epoch 163/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0431 - accuracy: 0.7620 - val_loss: 0.0423 - val_accuracy: 0.7739\n","Epoch 164/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.7645 - val_loss: 0.0421 - val_accuracy: 0.7761\n","Epoch 165/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0427 - accuracy: 0.7672 - val_loss: 0.0419 - val_accuracy: 0.7787\n","Epoch 166/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0425 - accuracy: 0.7689 - val_loss: 0.0417 - val_accuracy: 0.7810\n","Epoch 167/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0423 - accuracy: 0.7713 - val_loss: 0.0414 - val_accuracy: 0.7831\n","Epoch 168/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0420 - accuracy: 0.7732 - val_loss: 0.0412 - val_accuracy: 0.7848\n","Epoch 169/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0418 - accuracy: 0.7757 - val_loss: 0.0410 - val_accuracy: 0.7864\n","Epoch 170/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.7779 - val_loss: 0.0408 - val_accuracy: 0.7883\n","Epoch 171/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.7800 - val_loss: 0.0406 - val_accuracy: 0.7903\n","Epoch 172/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.7823 - val_loss: 0.0404 - val_accuracy: 0.7921\n","Epoch 173/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0410 - accuracy: 0.7845 - val_loss: 0.0401 - val_accuracy: 0.7939\n","Epoch 174/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0408 - accuracy: 0.7863 - val_loss: 0.0399 - val_accuracy: 0.7968\n","Epoch 175/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.7883 - val_loss: 0.0397 - val_accuracy: 0.7985\n","Epoch 176/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.7903 - val_loss: 0.0395 - val_accuracy: 0.8001\n","Epoch 177/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0402 - accuracy: 0.7925 - val_loss: 0.0393 - val_accuracy: 0.8031\n","Epoch 178/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0399 - accuracy: 0.7946 - val_loss: 0.0391 - val_accuracy: 0.8049\n","Epoch 179/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0397 - accuracy: 0.7965 - val_loss: 0.0389 - val_accuracy: 0.8071\n","Epoch 180/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0396 - accuracy: 0.7980 - val_loss: 0.0387 - val_accuracy: 0.8090\n","Epoch 181/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0394 - accuracy: 0.7995 - val_loss: 0.0385 - val_accuracy: 0.8106\n","Epoch 182/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.8015 - val_loss: 0.0383 - val_accuracy: 0.8122\n","Epoch 183/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0390 - accuracy: 0.8033 - val_loss: 0.0381 - val_accuracy: 0.8142\n","Epoch 184/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0388 - accuracy: 0.8049 - val_loss: 0.0379 - val_accuracy: 0.8153\n","Epoch 185/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0386 - accuracy: 0.8066 - val_loss: 0.0377 - val_accuracy: 0.8169\n","Epoch 186/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0384 - accuracy: 0.8080 - val_loss: 0.0375 - val_accuracy: 0.8179\n","Epoch 187/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0382 - accuracy: 0.8097 - val_loss: 0.0374 - val_accuracy: 0.8188\n","Epoch 188/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0380 - accuracy: 0.8112 - val_loss: 0.0372 - val_accuracy: 0.8201\n","Epoch 189/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0378 - accuracy: 0.8127 - val_loss: 0.0370 - val_accuracy: 0.8217\n","Epoch 190/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.8140 - val_loss: 0.0368 - val_accuracy: 0.8235\n","Epoch 191/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0375 - accuracy: 0.8151 - val_loss: 0.0366 - val_accuracy: 0.8248\n","Epoch 192/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.8166 - val_loss: 0.0364 - val_accuracy: 0.8258\n","Epoch 193/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0371 - accuracy: 0.8174 - val_loss: 0.0363 - val_accuracy: 0.8270\n","Epoch 194/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0369 - accuracy: 0.8191 - val_loss: 0.0361 - val_accuracy: 0.8282\n","Epoch 195/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0368 - accuracy: 0.8203 - val_loss: 0.0359 - val_accuracy: 0.8291\n","Epoch 196/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0366 - accuracy: 0.8211 - val_loss: 0.0357 - val_accuracy: 0.8307\n","Epoch 197/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0364 - accuracy: 0.8222 - val_loss: 0.0356 - val_accuracy: 0.8327\n","Epoch 198/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.8231 - val_loss: 0.0354 - val_accuracy: 0.8334\n","Epoch 199/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0361 - accuracy: 0.8246 - val_loss: 0.0352 - val_accuracy: 0.8344\n","Epoch 200/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0359 - accuracy: 0.8255 - val_loss: 0.0350 - val_accuracy: 0.8348\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ffa03439940>"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["In case in which I divided the number of neurons in dense by two, the accuracy didn't change that much. "],"metadata":{"id":"wUVRCcrTYmdo"}},{"cell_type":"code","source":["model3 = Sequential()\n","model3.add(Dense(64, activation='relu', input_shape=(784,)))\n","model3.add(Dense(10, activation='softmax'))"],"metadata":{"id":"5RyOMAvqYy3x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model3.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"],"metadata":{"id":"LMfqbxRSZGXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model3.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9o_iFQAvZKbL","executionInfo":{"status":"ok","timestamp":1679070856611,"user_tz":-60,"elapsed":442861,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"f8654706-1b2b-4c54-e450-c0e5186ad688"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0904 - accuracy: 0.1001 - val_loss: 0.0897 - val_accuracy: 0.1254\n","Epoch 2/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0886 - accuracy: 0.1644 - val_loss: 0.0878 - val_accuracy: 0.1993\n","Epoch 3/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0867 - accuracy: 0.2449 - val_loss: 0.0858 - val_accuracy: 0.2961\n","Epoch 4/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0847 - accuracy: 0.3361 - val_loss: 0.0836 - val_accuracy: 0.3839\n","Epoch 5/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.4208 - val_loss: 0.0810 - val_accuracy: 0.4601\n","Epoch 6/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.4847 - val_loss: 0.0781 - val_accuracy: 0.5126\n","Epoch 7/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0766 - accuracy: 0.5301 - val_loss: 0.0750 - val_accuracy: 0.5459\n","Epoch 8/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0733 - accuracy: 0.5616 - val_loss: 0.0716 - val_accuracy: 0.5769\n","Epoch 9/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0700 - accuracy: 0.5857 - val_loss: 0.0681 - val_accuracy: 0.6008\n","Epoch 10/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.6062 - val_loss: 0.0645 - val_accuracy: 0.6214\n","Epoch 11/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0631 - accuracy: 0.6247 - val_loss: 0.0611 - val_accuracy: 0.6408\n","Epoch 12/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.6404 - val_loss: 0.0579 - val_accuracy: 0.6529\n","Epoch 13/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0568 - accuracy: 0.6547 - val_loss: 0.0549 - val_accuracy: 0.6649\n","Epoch 14/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0541 - accuracy: 0.6669 - val_loss: 0.0522 - val_accuracy: 0.6759\n","Epoch 15/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.6791 - val_loss: 0.0497 - val_accuracy: 0.6893\n","Epoch 16/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0492 - accuracy: 0.6941 - val_loss: 0.0474 - val_accuracy: 0.7065\n","Epoch 17/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0470 - accuracy: 0.7129 - val_loss: 0.0453 - val_accuracy: 0.7304\n","Epoch 18/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.7338 - val_loss: 0.0432 - val_accuracy: 0.7525\n","Epoch 19/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0431 - accuracy: 0.7550 - val_loss: 0.0414 - val_accuracy: 0.7753\n","Epoch 20/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0414 - accuracy: 0.7727 - val_loss: 0.0396 - val_accuracy: 0.7905\n","Epoch 21/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.7866 - val_loss: 0.0380 - val_accuracy: 0.8038\n","Epoch 22/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.7976 - val_loss: 0.0366 - val_accuracy: 0.8144\n","Epoch 23/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0368 - accuracy: 0.8066 - val_loss: 0.0352 - val_accuracy: 0.8229\n","Epoch 24/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0356 - accuracy: 0.8146 - val_loss: 0.0340 - val_accuracy: 0.8302\n","Epoch 25/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.8203 - val_loss: 0.0328 - val_accuracy: 0.8351\n","Epoch 26/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0333 - accuracy: 0.8252 - val_loss: 0.0318 - val_accuracy: 0.8404\n","Epoch 27/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0323 - accuracy: 0.8305 - val_loss: 0.0308 - val_accuracy: 0.8440\n","Epoch 28/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0314 - accuracy: 0.8345 - val_loss: 0.0300 - val_accuracy: 0.8476\n","Epoch 29/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.8379 - val_loss: 0.0292 - val_accuracy: 0.8492\n","Epoch 30/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.8410 - val_loss: 0.0284 - val_accuracy: 0.8518\n","Epoch 31/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0291 - accuracy: 0.8438 - val_loss: 0.0277 - val_accuracy: 0.8535\n","Epoch 32/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0284 - accuracy: 0.8465 - val_loss: 0.0271 - val_accuracy: 0.8553\n","Epoch 33/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0278 - accuracy: 0.8493 - val_loss: 0.0265 - val_accuracy: 0.8577\n","Epoch 34/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0273 - accuracy: 0.8514 - val_loss: 0.0260 - val_accuracy: 0.8600\n","Epoch 35/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0267 - accuracy: 0.8537 - val_loss: 0.0254 - val_accuracy: 0.8609\n","Epoch 36/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0262 - accuracy: 0.8555 - val_loss: 0.0250 - val_accuracy: 0.8629\n","Epoch 37/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0258 - accuracy: 0.8573 - val_loss: 0.0245 - val_accuracy: 0.8644\n","Epoch 38/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0253 - accuracy: 0.8595 - val_loss: 0.0241 - val_accuracy: 0.8662\n","Epoch 39/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0249 - accuracy: 0.8612 - val_loss: 0.0237 - val_accuracy: 0.8680\n","Epoch 40/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0245 - accuracy: 0.8629 - val_loss: 0.0233 - val_accuracy: 0.8698\n","Epoch 41/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0242 - accuracy: 0.8649 - val_loss: 0.0230 - val_accuracy: 0.8708\n","Epoch 42/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.8658 - val_loss: 0.0227 - val_accuracy: 0.8731\n","Epoch 43/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0235 - accuracy: 0.8672 - val_loss: 0.0224 - val_accuracy: 0.8741\n","Epoch 44/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0232 - accuracy: 0.8686 - val_loss: 0.0221 - val_accuracy: 0.8750\n","Epoch 45/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.8697 - val_loss: 0.0218 - val_accuracy: 0.8767\n","Epoch 46/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0226 - accuracy: 0.8706 - val_loss: 0.0215 - val_accuracy: 0.8776\n","Epoch 47/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0224 - accuracy: 0.8717 - val_loss: 0.0213 - val_accuracy: 0.8789\n","Epoch 48/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0221 - accuracy: 0.8726 - val_loss: 0.0210 - val_accuracy: 0.8798\n","Epoch 49/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.8736 - val_loss: 0.0208 - val_accuracy: 0.8804\n","Epoch 50/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0217 - accuracy: 0.8746 - val_loss: 0.0206 - val_accuracy: 0.8813\n","Epoch 51/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0214 - accuracy: 0.8755 - val_loss: 0.0204 - val_accuracy: 0.8820\n","Epoch 52/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.8763 - val_loss: 0.0202 - val_accuracy: 0.8828\n","Epoch 53/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0210 - accuracy: 0.8774 - val_loss: 0.0200 - val_accuracy: 0.8833\n","Epoch 54/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.8779 - val_loss: 0.0198 - val_accuracy: 0.8840\n","Epoch 55/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0207 - accuracy: 0.8788 - val_loss: 0.0197 - val_accuracy: 0.8849\n","Epoch 56/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0205 - accuracy: 0.8795 - val_loss: 0.0195 - val_accuracy: 0.8855\n","Epoch 57/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0203 - accuracy: 0.8803 - val_loss: 0.0193 - val_accuracy: 0.8859\n","Epoch 58/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.8809 - val_loss: 0.0192 - val_accuracy: 0.8864\n","Epoch 59/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.8816 - val_loss: 0.0190 - val_accuracy: 0.8867\n","Epoch 60/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0199 - accuracy: 0.8824 - val_loss: 0.0189 - val_accuracy: 0.8876\n","Epoch 61/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0197 - accuracy: 0.8829 - val_loss: 0.0187 - val_accuracy: 0.8881\n","Epoch 62/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0196 - accuracy: 0.8838 - val_loss: 0.0186 - val_accuracy: 0.8889\n","Epoch 63/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0194 - accuracy: 0.8845 - val_loss: 0.0185 - val_accuracy: 0.8895\n","Epoch 64/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0193 - accuracy: 0.8849 - val_loss: 0.0183 - val_accuracy: 0.8909\n","Epoch 65/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.8856 - val_loss: 0.0182 - val_accuracy: 0.8912\n","Epoch 66/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.8861 - val_loss: 0.0181 - val_accuracy: 0.8913\n","Epoch 67/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0189 - accuracy: 0.8867 - val_loss: 0.0180 - val_accuracy: 0.8919\n","Epoch 68/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.8871 - val_loss: 0.0179 - val_accuracy: 0.8922\n","Epoch 69/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.8876 - val_loss: 0.0178 - val_accuracy: 0.8927\n","Epoch 70/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.8881 - val_loss: 0.0177 - val_accuracy: 0.8932\n","Epoch 71/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.8887 - val_loss: 0.0176 - val_accuracy: 0.8936\n","Epoch 72/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0184 - accuracy: 0.8893 - val_loss: 0.0175 - val_accuracy: 0.8940\n","Epoch 73/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0183 - accuracy: 0.8896 - val_loss: 0.0174 - val_accuracy: 0.8944\n","Epoch 74/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0182 - accuracy: 0.8901 - val_loss: 0.0173 - val_accuracy: 0.8954\n","Epoch 75/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0181 - accuracy: 0.8906 - val_loss: 0.0172 - val_accuracy: 0.8954\n","Epoch 76/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.8911 - val_loss: 0.0171 - val_accuracy: 0.8958\n","Epoch 77/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0179 - accuracy: 0.8915 - val_loss: 0.0170 - val_accuracy: 0.8968\n","Epoch 78/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0178 - accuracy: 0.8921 - val_loss: 0.0169 - val_accuracy: 0.8972\n","Epoch 79/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0177 - accuracy: 0.8926 - val_loss: 0.0168 - val_accuracy: 0.8975\n","Epoch 80/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0176 - accuracy: 0.8930 - val_loss: 0.0168 - val_accuracy: 0.8974\n","Epoch 81/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0175 - accuracy: 0.8933 - val_loss: 0.0167 - val_accuracy: 0.8981\n","Epoch 82/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0175 - accuracy: 0.8938 - val_loss: 0.0166 - val_accuracy: 0.8981\n","Epoch 83/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0174 - accuracy: 0.8941 - val_loss: 0.0165 - val_accuracy: 0.8984\n","Epoch 84/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0173 - accuracy: 0.8942 - val_loss: 0.0165 - val_accuracy: 0.8990\n","Epoch 85/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0172 - accuracy: 0.8946 - val_loss: 0.0164 - val_accuracy: 0.8990\n","Epoch 86/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.8951 - val_loss: 0.0163 - val_accuracy: 0.8992\n","Epoch 87/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0171 - accuracy: 0.8954 - val_loss: 0.0163 - val_accuracy: 0.8997\n","Epoch 88/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0170 - accuracy: 0.8959 - val_loss: 0.0162 - val_accuracy: 0.8999\n","Epoch 89/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0169 - accuracy: 0.8962 - val_loss: 0.0161 - val_accuracy: 0.9002\n","Epoch 90/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0169 - accuracy: 0.8967 - val_loss: 0.0161 - val_accuracy: 0.9007\n","Epoch 91/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0168 - accuracy: 0.8970 - val_loss: 0.0160 - val_accuracy: 0.9008\n","Epoch 92/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.8974 - val_loss: 0.0159 - val_accuracy: 0.9015\n","Epoch 93/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.8978 - val_loss: 0.0159 - val_accuracy: 0.9016\n","Epoch 94/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0166 - accuracy: 0.8978 - val_loss: 0.0158 - val_accuracy: 0.9018\n","Epoch 95/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0166 - accuracy: 0.8984 - val_loss: 0.0158 - val_accuracy: 0.9021\n","Epoch 96/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0165 - accuracy: 0.8989 - val_loss: 0.0157 - val_accuracy: 0.9028\n","Epoch 97/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0164 - accuracy: 0.8992 - val_loss: 0.0156 - val_accuracy: 0.9030\n","Epoch 98/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0164 - accuracy: 0.8994 - val_loss: 0.0156 - val_accuracy: 0.9031\n","Epoch 99/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0163 - accuracy: 0.8997 - val_loss: 0.0155 - val_accuracy: 0.9035\n","Epoch 100/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0163 - accuracy: 0.8999 - val_loss: 0.0155 - val_accuracy: 0.9031\n","Epoch 101/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9002 - val_loss: 0.0154 - val_accuracy: 0.9036\n","Epoch 102/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0161 - accuracy: 0.9005 - val_loss: 0.0154 - val_accuracy: 0.9040\n","Epoch 103/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0161 - accuracy: 0.9009 - val_loss: 0.0153 - val_accuracy: 0.9043\n","Epoch 104/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0160 - accuracy: 0.9012 - val_loss: 0.0153 - val_accuracy: 0.9047\n","Epoch 105/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0160 - accuracy: 0.9013 - val_loss: 0.0152 - val_accuracy: 0.9047\n","Epoch 106/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9017 - val_loss: 0.0152 - val_accuracy: 0.9052\n","Epoch 107/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9019 - val_loss: 0.0151 - val_accuracy: 0.9058\n","Epoch 108/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0158 - accuracy: 0.9021 - val_loss: 0.0151 - val_accuracy: 0.9059\n","Epoch 109/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0158 - accuracy: 0.9026 - val_loss: 0.0150 - val_accuracy: 0.9061\n","Epoch 110/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9029 - val_loss: 0.0150 - val_accuracy: 0.9063\n","Epoch 111/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0157 - accuracy: 0.9030 - val_loss: 0.0150 - val_accuracy: 0.9065\n","Epoch 112/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0156 - accuracy: 0.9034 - val_loss: 0.0149 - val_accuracy: 0.9070\n","Epoch 113/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0156 - accuracy: 0.9038 - val_loss: 0.0149 - val_accuracy: 0.9073\n","Epoch 114/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0156 - accuracy: 0.9038 - val_loss: 0.0148 - val_accuracy: 0.9078\n","Epoch 115/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0155 - accuracy: 0.9043 - val_loss: 0.0148 - val_accuracy: 0.9083\n","Epoch 116/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9044 - val_loss: 0.0147 - val_accuracy: 0.9082\n","Epoch 117/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0154 - accuracy: 0.9046 - val_loss: 0.0147 - val_accuracy: 0.9084\n","Epoch 118/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0154 - accuracy: 0.9049 - val_loss: 0.0147 - val_accuracy: 0.9089\n","Epoch 119/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0153 - accuracy: 0.9050 - val_loss: 0.0146 - val_accuracy: 0.9090\n","Epoch 120/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0153 - accuracy: 0.9052 - val_loss: 0.0146 - val_accuracy: 0.9093\n","Epoch 121/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0152 - accuracy: 0.9054 - val_loss: 0.0145 - val_accuracy: 0.9095\n","Epoch 122/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0152 - accuracy: 0.9057 - val_loss: 0.0145 - val_accuracy: 0.9095\n","Epoch 123/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0152 - accuracy: 0.9059 - val_loss: 0.0145 - val_accuracy: 0.9097\n","Epoch 124/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0151 - accuracy: 0.9060 - val_loss: 0.0144 - val_accuracy: 0.9098\n","Epoch 125/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0151 - accuracy: 0.9064 - val_loss: 0.0144 - val_accuracy: 0.9103\n","Epoch 126/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9064 - val_loss: 0.0144 - val_accuracy: 0.9102\n","Epoch 127/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9067 - val_loss: 0.0143 - val_accuracy: 0.9105\n","Epoch 128/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9068 - val_loss: 0.0143 - val_accuracy: 0.9105\n","Epoch 129/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0149 - accuracy: 0.9070 - val_loss: 0.0142 - val_accuracy: 0.9109\n","Epoch 130/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9073 - val_loss: 0.0142 - val_accuracy: 0.9114\n","Epoch 131/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9075 - val_loss: 0.0142 - val_accuracy: 0.9114\n","Epoch 132/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0148 - accuracy: 0.9077 - val_loss: 0.0142 - val_accuracy: 0.9117\n","Epoch 133/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0148 - accuracy: 0.9079 - val_loss: 0.0141 - val_accuracy: 0.9116\n","Epoch 134/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0148 - accuracy: 0.9082 - val_loss: 0.0141 - val_accuracy: 0.9120\n","Epoch 135/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0147 - accuracy: 0.9082 - val_loss: 0.0141 - val_accuracy: 0.9120\n","Epoch 136/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0147 - accuracy: 0.9085 - val_loss: 0.0140 - val_accuracy: 0.9121\n","Epoch 137/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0146 - accuracy: 0.9086 - val_loss: 0.0140 - val_accuracy: 0.9123\n","Epoch 138/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0146 - accuracy: 0.9086 - val_loss: 0.0140 - val_accuracy: 0.9126\n","Epoch 139/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0146 - accuracy: 0.9089 - val_loss: 0.0139 - val_accuracy: 0.9126\n","Epoch 140/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0145 - accuracy: 0.9092 - val_loss: 0.0139 - val_accuracy: 0.9126\n","Epoch 141/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9094 - val_loss: 0.0139 - val_accuracy: 0.9126\n","Epoch 142/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9098 - val_loss: 0.0138 - val_accuracy: 0.9124\n","Epoch 143/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0144 - accuracy: 0.9098 - val_loss: 0.0138 - val_accuracy: 0.9128\n","Epoch 144/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0144 - accuracy: 0.9099 - val_loss: 0.0138 - val_accuracy: 0.9122\n","Epoch 145/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0144 - accuracy: 0.9101 - val_loss: 0.0138 - val_accuracy: 0.9132\n","Epoch 146/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0144 - accuracy: 0.9104 - val_loss: 0.0137 - val_accuracy: 0.9130\n","Epoch 147/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9106 - val_loss: 0.0137 - val_accuracy: 0.9135\n","Epoch 148/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0143 - accuracy: 0.9106 - val_loss: 0.0137 - val_accuracy: 0.9139\n","Epoch 149/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9108 - val_loss: 0.0136 - val_accuracy: 0.9139\n","Epoch 150/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0142 - accuracy: 0.9110 - val_loss: 0.0136 - val_accuracy: 0.9144\n","Epoch 151/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0142 - accuracy: 0.9113 - val_loss: 0.0136 - val_accuracy: 0.9145\n","Epoch 152/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0142 - accuracy: 0.9113 - val_loss: 0.0136 - val_accuracy: 0.9146\n","Epoch 153/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.9115 - val_loss: 0.0135 - val_accuracy: 0.9149\n","Epoch 154/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0141 - accuracy: 0.9116 - val_loss: 0.0135 - val_accuracy: 0.9148\n","Epoch 155/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0141 - accuracy: 0.9118 - val_loss: 0.0135 - val_accuracy: 0.9150\n","Epoch 156/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.9118 - val_loss: 0.0135 - val_accuracy: 0.9153\n","Epoch 157/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9120 - val_loss: 0.0134 - val_accuracy: 0.9154\n","Epoch 158/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9122 - val_loss: 0.0134 - val_accuracy: 0.9155\n","Epoch 159/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0140 - accuracy: 0.9125 - val_loss: 0.0134 - val_accuracy: 0.9155\n","Epoch 160/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0139 - accuracy: 0.9125 - val_loss: 0.0133 - val_accuracy: 0.9157\n","Epoch 161/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0139 - accuracy: 0.9126 - val_loss: 0.0133 - val_accuracy: 0.9158\n","Epoch 162/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9126 - val_loss: 0.0133 - val_accuracy: 0.9159\n","Epoch 163/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9130 - val_loss: 0.0133 - val_accuracy: 0.9157\n","Epoch 164/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9130 - val_loss: 0.0133 - val_accuracy: 0.9157\n","Epoch 165/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9132 - val_loss: 0.0132 - val_accuracy: 0.9160\n","Epoch 166/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0138 - accuracy: 0.9134 - val_loss: 0.0132 - val_accuracy: 0.9163\n","Epoch 167/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0138 - accuracy: 0.9136 - val_loss: 0.0132 - val_accuracy: 0.9162\n","Epoch 168/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9136 - val_loss: 0.0132 - val_accuracy: 0.9162\n","Epoch 169/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0137 - accuracy: 0.9139 - val_loss: 0.0131 - val_accuracy: 0.9166\n","Epoch 170/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9140 - val_loss: 0.0131 - val_accuracy: 0.9166\n","Epoch 171/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9143 - val_loss: 0.0131 - val_accuracy: 0.9168\n","Epoch 172/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9145 - val_loss: 0.0131 - val_accuracy: 0.9171\n","Epoch 173/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0136 - accuracy: 0.9146 - val_loss: 0.0130 - val_accuracy: 0.9172\n","Epoch 174/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9148 - val_loss: 0.0130 - val_accuracy: 0.9173\n","Epoch 175/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9150 - val_loss: 0.0130 - val_accuracy: 0.9176\n","Epoch 176/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9151 - val_loss: 0.0130 - val_accuracy: 0.9174\n","Epoch 177/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9152 - val_loss: 0.0130 - val_accuracy: 0.9178\n","Epoch 178/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0135 - accuracy: 0.9154 - val_loss: 0.0129 - val_accuracy: 0.9179\n","Epoch 179/200\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9156 - val_loss: 0.0129 - val_accuracy: 0.9177\n","Epoch 180/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0134 - accuracy: 0.9156 - val_loss: 0.0129 - val_accuracy: 0.9183\n","Epoch 181/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0134 - accuracy: 0.9159 - val_loss: 0.0129 - val_accuracy: 0.9184\n","Epoch 182/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0134 - accuracy: 0.9160 - val_loss: 0.0129 - val_accuracy: 0.9185\n","Epoch 183/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0134 - accuracy: 0.9162 - val_loss: 0.0128 - val_accuracy: 0.9187\n","Epoch 184/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9162 - val_loss: 0.0128 - val_accuracy: 0.9190\n","Epoch 185/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0133 - accuracy: 0.9164 - val_loss: 0.0128 - val_accuracy: 0.9190\n","Epoch 186/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9165 - val_loss: 0.0128 - val_accuracy: 0.9195\n","Epoch 187/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9167 - val_loss: 0.0128 - val_accuracy: 0.9195\n","Epoch 188/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9168 - val_loss: 0.0127 - val_accuracy: 0.9197\n","Epoch 189/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9170 - val_loss: 0.0127 - val_accuracy: 0.9197\n","Epoch 190/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9172 - val_loss: 0.0127 - val_accuracy: 0.9201\n","Epoch 191/200\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0132 - accuracy: 0.9171 - val_loss: 0.0127 - val_accuracy: 0.9199\n","Epoch 192/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0132 - accuracy: 0.9174 - val_loss: 0.0127 - val_accuracy: 0.9201\n","Epoch 193/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0131 - accuracy: 0.9176 - val_loss: 0.0126 - val_accuracy: 0.9205\n","Epoch 194/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9176 - val_loss: 0.0126 - val_accuracy: 0.9204\n","Epoch 195/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9177 - val_loss: 0.0126 - val_accuracy: 0.9205\n","Epoch 196/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0131 - accuracy: 0.9179 - val_loss: 0.0126 - val_accuracy: 0.9206\n","Epoch 197/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0130 - accuracy: 0.9181 - val_loss: 0.0126 - val_accuracy: 0.9207\n","Epoch 198/200\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0130 - accuracy: 0.9182 - val_loss: 0.0125 - val_accuracy: 0.9208\n","Epoch 199/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0130 - accuracy: 0.9182 - val_loss: 0.0125 - val_accuracy: 0.9209\n","Epoch 200/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0130 - accuracy: 0.9185 - val_loss: 0.0125 - val_accuracy: 0.9209\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ffa032f10a0>"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["Model with different type of neurons got over 90% accuracy."],"metadata":{"id":"n5UZTIERbBEZ"}},{"cell_type":"code","source":["model4 = Sequential()\n","model4.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n","model4.add(Dense(10, activation='softmax'))"],"metadata":{"id":"vmrYnobtbHlN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model4.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"],"metadata":{"id":"OmpcRWTEbTcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model4.fit(X_train, y_train, batch_size=64, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozBPhZa_batz","executionInfo":{"status":"ok","timestamp":1679071670698,"user_tz":-60,"elapsed":683617,"user":{"displayName":"Adam Młyńczak","userId":"00622532244001944002"}},"outputId":"d1584be5-74f7-416d-baeb-aa21466a3fa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","938/938 [==============================] - 4s 3ms/step - loss: 0.0918 - accuracy: 0.1378 - val_loss: 0.0909 - val_accuracy: 0.1941\n","Epoch 2/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0904 - accuracy: 0.2160 - val_loss: 0.0898 - val_accuracy: 0.2461\n","Epoch 3/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0894 - accuracy: 0.2382 - val_loss: 0.0889 - val_accuracy: 0.2674\n","Epoch 4/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0885 - accuracy: 0.2666 - val_loss: 0.0880 - val_accuracy: 0.2918\n","Epoch 5/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0877 - accuracy: 0.2916 - val_loss: 0.0873 - val_accuracy: 0.3074\n","Epoch 6/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0870 - accuracy: 0.3041 - val_loss: 0.0865 - val_accuracy: 0.3179\n","Epoch 7/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0862 - accuracy: 0.3131 - val_loss: 0.0857 - val_accuracy: 0.3286\n","Epoch 8/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0855 - accuracy: 0.3248 - val_loss: 0.0850 - val_accuracy: 0.3376\n","Epoch 9/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0847 - accuracy: 0.3316 - val_loss: 0.0842 - val_accuracy: 0.3513\n","Epoch 10/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.3456 - val_loss: 0.0834 - val_accuracy: 0.3657\n","Epoch 11/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.3601 - val_loss: 0.0825 - val_accuracy: 0.3782\n","Epoch 12/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.3772 - val_loss: 0.0817 - val_accuracy: 0.3897\n","Epoch 13/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0815 - accuracy: 0.3898 - val_loss: 0.0808 - val_accuracy: 0.4055\n","Epoch 14/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0806 - accuracy: 0.4063 - val_loss: 0.0799 - val_accuracy: 0.4210\n","Epoch 15/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0797 - accuracy: 0.4242 - val_loss: 0.0790 - val_accuracy: 0.4377\n","Epoch 16/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0788 - accuracy: 0.4414 - val_loss: 0.0780 - val_accuracy: 0.4585\n","Epoch 17/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0779 - accuracy: 0.4622 - val_loss: 0.0771 - val_accuracy: 0.4790\n","Epoch 18/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0769 - accuracy: 0.4839 - val_loss: 0.0761 - val_accuracy: 0.5010\n","Epoch 19/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0760 - accuracy: 0.5030 - val_loss: 0.0752 - val_accuracy: 0.5228\n","Epoch 20/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0750 - accuracy: 0.5225 - val_loss: 0.0742 - val_accuracy: 0.5440\n","Epoch 21/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0741 - accuracy: 0.5422 - val_loss: 0.0732 - val_accuracy: 0.5644\n","Epoch 22/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0731 - accuracy: 0.5617 - val_loss: 0.0722 - val_accuracy: 0.5791\n","Epoch 23/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0721 - accuracy: 0.5776 - val_loss: 0.0712 - val_accuracy: 0.5922\n","Epoch 24/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0711 - accuracy: 0.5915 - val_loss: 0.0702 - val_accuracy: 0.6067\n","Epoch 25/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0701 - accuracy: 0.6030 - val_loss: 0.0692 - val_accuracy: 0.6160\n","Epoch 26/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0692 - accuracy: 0.6131 - val_loss: 0.0682 - val_accuracy: 0.6267\n","Epoch 27/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0682 - accuracy: 0.6221 - val_loss: 0.0672 - val_accuracy: 0.6353\n","Epoch 28/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0672 - accuracy: 0.6283 - val_loss: 0.0662 - val_accuracy: 0.6422\n","Epoch 29/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0662 - accuracy: 0.6350 - val_loss: 0.0652 - val_accuracy: 0.6466\n","Epoch 30/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0652 - accuracy: 0.6396 - val_loss: 0.0642 - val_accuracy: 0.6528\n","Epoch 31/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0642 - accuracy: 0.6448 - val_loss: 0.0632 - val_accuracy: 0.6581\n","Epoch 32/200\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0632 - accuracy: 0.6504 - val_loss: 0.0622 - val_accuracy: 0.6635\n","Epoch 33/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0622 - accuracy: 0.6550 - val_loss: 0.0612 - val_accuracy: 0.6685\n","Epoch 34/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0613 - accuracy: 0.6596 - val_loss: 0.0603 - val_accuracy: 0.6723\n","Epoch 35/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0603 - accuracy: 0.6635 - val_loss: 0.0593 - val_accuracy: 0.6772\n","Epoch 36/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0594 - accuracy: 0.6683 - val_loss: 0.0584 - val_accuracy: 0.6799\n","Epoch 37/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0585 - accuracy: 0.6724 - val_loss: 0.0575 - val_accuracy: 0.6839\n","Epoch 38/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0576 - accuracy: 0.6762 - val_loss: 0.0566 - val_accuracy: 0.6876\n","Epoch 39/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0567 - accuracy: 0.6798 - val_loss: 0.0557 - val_accuracy: 0.6913\n","Epoch 40/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0559 - accuracy: 0.6839 - val_loss: 0.0549 - val_accuracy: 0.6948\n","Epoch 41/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0551 - accuracy: 0.6874 - val_loss: 0.0541 - val_accuracy: 0.6982\n","Epoch 42/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0542 - accuracy: 0.6916 - val_loss: 0.0533 - val_accuracy: 0.7015\n","Epoch 43/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0535 - accuracy: 0.6954 - val_loss: 0.0525 - val_accuracy: 0.7060\n","Epoch 44/200\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0527 - accuracy: 0.6993 - val_loss: 0.0517 - val_accuracy: 0.7099\n","Epoch 45/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0520 - accuracy: 0.7029 - val_loss: 0.0510 - val_accuracy: 0.7145\n","Epoch 46/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0512 - accuracy: 0.7066 - val_loss: 0.0503 - val_accuracy: 0.7175\n","Epoch 47/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0505 - accuracy: 0.7104 - val_loss: 0.0495 - val_accuracy: 0.7217\n","Epoch 48/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0498 - accuracy: 0.7147 - val_loss: 0.0489 - val_accuracy: 0.7263\n","Epoch 49/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0492 - accuracy: 0.7192 - val_loss: 0.0482 - val_accuracy: 0.7315\n","Epoch 50/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0485 - accuracy: 0.7237 - val_loss: 0.0475 - val_accuracy: 0.7360\n","Epoch 51/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0479 - accuracy: 0.7278 - val_loss: 0.0469 - val_accuracy: 0.7399\n","Epoch 52/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0473 - accuracy: 0.7319 - val_loss: 0.0463 - val_accuracy: 0.7445\n","Epoch 53/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0467 - accuracy: 0.7362 - val_loss: 0.0457 - val_accuracy: 0.7471\n","Epoch 54/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0461 - accuracy: 0.7402 - val_loss: 0.0451 - val_accuracy: 0.7513\n","Epoch 55/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0455 - accuracy: 0.7440 - val_loss: 0.0445 - val_accuracy: 0.7550\n","Epoch 56/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0449 - accuracy: 0.7476 - val_loss: 0.0439 - val_accuracy: 0.7581\n","Epoch 57/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0444 - accuracy: 0.7508 - val_loss: 0.0434 - val_accuracy: 0.7618\n","Epoch 58/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0438 - accuracy: 0.7532 - val_loss: 0.0429 - val_accuracy: 0.7655\n","Epoch 59/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0433 - accuracy: 0.7568 - val_loss: 0.0423 - val_accuracy: 0.7680\n","Epoch 60/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0428 - accuracy: 0.7601 - val_loss: 0.0418 - val_accuracy: 0.7712\n","Epoch 61/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0423 - accuracy: 0.7626 - val_loss: 0.0413 - val_accuracy: 0.7745\n","Epoch 62/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0418 - accuracy: 0.7652 - val_loss: 0.0408 - val_accuracy: 0.7765\n","Epoch 63/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0413 - accuracy: 0.7681 - val_loss: 0.0403 - val_accuracy: 0.7796\n","Epoch 64/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0408 - accuracy: 0.7706 - val_loss: 0.0399 - val_accuracy: 0.7819\n","Epoch 65/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0404 - accuracy: 0.7727 - val_loss: 0.0394 - val_accuracy: 0.7833\n","Epoch 66/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0399 - accuracy: 0.7746 - val_loss: 0.0389 - val_accuracy: 0.7853\n","Epoch 67/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0395 - accuracy: 0.7765 - val_loss: 0.0385 - val_accuracy: 0.7878\n","Epoch 68/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0390 - accuracy: 0.7790 - val_loss: 0.0381 - val_accuracy: 0.7890\n","Epoch 69/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.7813 - val_loss: 0.0376 - val_accuracy: 0.7912\n","Epoch 70/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0382 - accuracy: 0.7845 - val_loss: 0.0372 - val_accuracy: 0.7942\n","Epoch 71/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0378 - accuracy: 0.7866 - val_loss: 0.0368 - val_accuracy: 0.7963\n","Epoch 72/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0374 - accuracy: 0.7901 - val_loss: 0.0364 - val_accuracy: 0.8002\n","Epoch 73/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0370 - accuracy: 0.7930 - val_loss: 0.0360 - val_accuracy: 0.8021\n","Epoch 74/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0366 - accuracy: 0.7958 - val_loss: 0.0356 - val_accuracy: 0.8052\n","Epoch 75/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0362 - accuracy: 0.7987 - val_loss: 0.0353 - val_accuracy: 0.8094\n","Epoch 76/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0359 - accuracy: 0.8013 - val_loss: 0.0349 - val_accuracy: 0.8128\n","Epoch 77/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0355 - accuracy: 0.8048 - val_loss: 0.0345 - val_accuracy: 0.8153\n","Epoch 78/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0352 - accuracy: 0.8078 - val_loss: 0.0342 - val_accuracy: 0.8174\n","Epoch 79/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0348 - accuracy: 0.8105 - val_loss: 0.0338 - val_accuracy: 0.8191\n","Epoch 80/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0345 - accuracy: 0.8128 - val_loss: 0.0335 - val_accuracy: 0.8224\n","Epoch 81/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0342 - accuracy: 0.8163 - val_loss: 0.0332 - val_accuracy: 0.8245\n","Epoch 82/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0338 - accuracy: 0.8186 - val_loss: 0.0328 - val_accuracy: 0.8271\n","Epoch 83/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0335 - accuracy: 0.8219 - val_loss: 0.0325 - val_accuracy: 0.8301\n","Epoch 84/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0332 - accuracy: 0.8242 - val_loss: 0.0322 - val_accuracy: 0.8336\n","Epoch 85/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0329 - accuracy: 0.8264 - val_loss: 0.0319 - val_accuracy: 0.8357\n","Epoch 86/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0326 - accuracy: 0.8284 - val_loss: 0.0316 - val_accuracy: 0.8383\n","Epoch 87/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0323 - accuracy: 0.8311 - val_loss: 0.0313 - val_accuracy: 0.8401\n","Epoch 88/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0320 - accuracy: 0.8336 - val_loss: 0.0310 - val_accuracy: 0.8414\n","Epoch 89/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0317 - accuracy: 0.8354 - val_loss: 0.0307 - val_accuracy: 0.8436\n","Epoch 90/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0315 - accuracy: 0.8378 - val_loss: 0.0305 - val_accuracy: 0.8451\n","Epoch 91/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0312 - accuracy: 0.8396 - val_loss: 0.0302 - val_accuracy: 0.8467\n","Epoch 92/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0309 - accuracy: 0.8418 - val_loss: 0.0299 - val_accuracy: 0.8492\n","Epoch 93/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0307 - accuracy: 0.8438 - val_loss: 0.0297 - val_accuracy: 0.8510\n","Epoch 94/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0304 - accuracy: 0.8451 - val_loss: 0.0294 - val_accuracy: 0.8527\n","Epoch 95/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0301 - accuracy: 0.8470 - val_loss: 0.0292 - val_accuracy: 0.8540\n","Epoch 96/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0299 - accuracy: 0.8485 - val_loss: 0.0289 - val_accuracy: 0.8558\n","Epoch 97/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0297 - accuracy: 0.8499 - val_loss: 0.0287 - val_accuracy: 0.8574\n","Epoch 98/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0294 - accuracy: 0.8512 - val_loss: 0.0284 - val_accuracy: 0.8587\n","Epoch 99/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0292 - accuracy: 0.8526 - val_loss: 0.0282 - val_accuracy: 0.8594\n","Epoch 100/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0290 - accuracy: 0.8535 - val_loss: 0.0280 - val_accuracy: 0.8608\n","Epoch 101/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0287 - accuracy: 0.8545 - val_loss: 0.0278 - val_accuracy: 0.8615\n","Epoch 102/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0285 - accuracy: 0.8558 - val_loss: 0.0275 - val_accuracy: 0.8623\n","Epoch 103/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0283 - accuracy: 0.8566 - val_loss: 0.0273 - val_accuracy: 0.8630\n","Epoch 104/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0281 - accuracy: 0.8576 - val_loss: 0.0271 - val_accuracy: 0.8634\n","Epoch 105/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0279 - accuracy: 0.8586 - val_loss: 0.0269 - val_accuracy: 0.8646\n","Epoch 106/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0277 - accuracy: 0.8595 - val_loss: 0.0267 - val_accuracy: 0.8655\n","Epoch 107/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0275 - accuracy: 0.8604 - val_loss: 0.0265 - val_accuracy: 0.8665\n","Epoch 108/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0273 - accuracy: 0.8615 - val_loss: 0.0263 - val_accuracy: 0.8678\n","Epoch 109/200\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0271 - accuracy: 0.8623 - val_loss: 0.0261 - val_accuracy: 0.8687\n","Epoch 110/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0269 - accuracy: 0.8627 - val_loss: 0.0260 - val_accuracy: 0.8696\n","Epoch 111/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0268 - accuracy: 0.8638 - val_loss: 0.0258 - val_accuracy: 0.8708\n","Epoch 112/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0266 - accuracy: 0.8645 - val_loss: 0.0256 - val_accuracy: 0.8713\n","Epoch 113/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0264 - accuracy: 0.8653 - val_loss: 0.0254 - val_accuracy: 0.8719\n","Epoch 114/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0262 - accuracy: 0.8658 - val_loss: 0.0253 - val_accuracy: 0.8725\n","Epoch 115/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0261 - accuracy: 0.8662 - val_loss: 0.0251 - val_accuracy: 0.8733\n","Epoch 116/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0259 - accuracy: 0.8669 - val_loss: 0.0249 - val_accuracy: 0.8738\n","Epoch 117/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0257 - accuracy: 0.8674 - val_loss: 0.0248 - val_accuracy: 0.8744\n","Epoch 118/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0256 - accuracy: 0.8684 - val_loss: 0.0246 - val_accuracy: 0.8748\n","Epoch 119/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0254 - accuracy: 0.8687 - val_loss: 0.0245 - val_accuracy: 0.8754\n","Epoch 120/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0253 - accuracy: 0.8697 - val_loss: 0.0243 - val_accuracy: 0.8753\n","Epoch 121/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0251 - accuracy: 0.8702 - val_loss: 0.0242 - val_accuracy: 0.8761\n","Epoch 122/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0250 - accuracy: 0.8706 - val_loss: 0.0240 - val_accuracy: 0.8763\n","Epoch 123/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0248 - accuracy: 0.8709 - val_loss: 0.0239 - val_accuracy: 0.8773\n","Epoch 124/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0247 - accuracy: 0.8714 - val_loss: 0.0237 - val_accuracy: 0.8780\n","Epoch 125/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0246 - accuracy: 0.8722 - val_loss: 0.0236 - val_accuracy: 0.8780\n","Epoch 126/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0244 - accuracy: 0.8725 - val_loss: 0.0235 - val_accuracy: 0.8784\n","Epoch 127/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0243 - accuracy: 0.8732 - val_loss: 0.0233 - val_accuracy: 0.8789\n","Epoch 128/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0242 - accuracy: 0.8735 - val_loss: 0.0232 - val_accuracy: 0.8790\n","Epoch 129/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0240 - accuracy: 0.8742 - val_loss: 0.0231 - val_accuracy: 0.8795\n","Epoch 130/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0239 - accuracy: 0.8746 - val_loss: 0.0230 - val_accuracy: 0.8799\n","Epoch 131/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0238 - accuracy: 0.8750 - val_loss: 0.0228 - val_accuracy: 0.8801\n","Epoch 132/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0237 - accuracy: 0.8755 - val_loss: 0.0227 - val_accuracy: 0.8810\n","Epoch 133/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0236 - accuracy: 0.8756 - val_loss: 0.0226 - val_accuracy: 0.8814\n","Epoch 134/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0234 - accuracy: 0.8760 - val_loss: 0.0225 - val_accuracy: 0.8821\n","Epoch 135/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0233 - accuracy: 0.8763 - val_loss: 0.0224 - val_accuracy: 0.8824\n","Epoch 136/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0232 - accuracy: 0.8766 - val_loss: 0.0223 - val_accuracy: 0.8824\n","Epoch 137/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0231 - accuracy: 0.8768 - val_loss: 0.0222 - val_accuracy: 0.8829\n","Epoch 138/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0230 - accuracy: 0.8773 - val_loss: 0.0221 - val_accuracy: 0.8830\n","Epoch 139/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0229 - accuracy: 0.8779 - val_loss: 0.0220 - val_accuracy: 0.8835\n","Epoch 140/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.8782 - val_loss: 0.0219 - val_accuracy: 0.8840\n","Epoch 141/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.8785 - val_loss: 0.0218 - val_accuracy: 0.8842\n","Epoch 142/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0226 - accuracy: 0.8787 - val_loss: 0.0217 - val_accuracy: 0.8846\n","Epoch 143/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0225 - accuracy: 0.8790 - val_loss: 0.0216 - val_accuracy: 0.8850\n","Epoch 144/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0224 - accuracy: 0.8793 - val_loss: 0.0215 - val_accuracy: 0.8856\n","Epoch 145/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0223 - accuracy: 0.8798 - val_loss: 0.0214 - val_accuracy: 0.8865\n","Epoch 146/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0222 - accuracy: 0.8802 - val_loss: 0.0213 - val_accuracy: 0.8867\n","Epoch 147/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0221 - accuracy: 0.8804 - val_loss: 0.0212 - val_accuracy: 0.8871\n","Epoch 148/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0220 - accuracy: 0.8806 - val_loss: 0.0211 - val_accuracy: 0.8874\n","Epoch 149/200\n","938/938 [==============================] - 5s 5ms/step - loss: 0.0219 - accuracy: 0.8809 - val_loss: 0.0210 - val_accuracy: 0.8875\n","Epoch 150/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0218 - accuracy: 0.8811 - val_loss: 0.0209 - val_accuracy: 0.8876\n","Epoch 151/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0218 - accuracy: 0.8813 - val_loss: 0.0208 - val_accuracy: 0.8880\n","Epoch 152/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0217 - accuracy: 0.8817 - val_loss: 0.0208 - val_accuracy: 0.8879\n","Epoch 153/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0216 - accuracy: 0.8820 - val_loss: 0.0207 - val_accuracy: 0.8881\n","Epoch 154/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0215 - accuracy: 0.8821 - val_loss: 0.0206 - val_accuracy: 0.8885\n","Epoch 155/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0214 - accuracy: 0.8826 - val_loss: 0.0205 - val_accuracy: 0.8888\n","Epoch 156/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0213 - accuracy: 0.8828 - val_loss: 0.0204 - val_accuracy: 0.8890\n","Epoch 157/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0213 - accuracy: 0.8831 - val_loss: 0.0204 - val_accuracy: 0.8891\n","Epoch 158/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0212 - accuracy: 0.8833 - val_loss: 0.0203 - val_accuracy: 0.8894\n","Epoch 159/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0211 - accuracy: 0.8835 - val_loss: 0.0202 - val_accuracy: 0.8897\n","Epoch 160/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0210 - accuracy: 0.8837 - val_loss: 0.0201 - val_accuracy: 0.8900\n","Epoch 161/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0210 - accuracy: 0.8841 - val_loss: 0.0201 - val_accuracy: 0.8904\n","Epoch 162/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0209 - accuracy: 0.8844 - val_loss: 0.0200 - val_accuracy: 0.8905\n","Epoch 163/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0208 - accuracy: 0.8845 - val_loss: 0.0199 - val_accuracy: 0.8906\n","Epoch 164/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0208 - accuracy: 0.8848 - val_loss: 0.0198 - val_accuracy: 0.8908\n","Epoch 165/200\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0207 - accuracy: 0.8850 - val_loss: 0.0198 - val_accuracy: 0.8909\n","Epoch 166/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0206 - accuracy: 0.8853 - val_loss: 0.0197 - val_accuracy: 0.8910\n","Epoch 167/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.8855 - val_loss: 0.0196 - val_accuracy: 0.8912\n","Epoch 168/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.8858 - val_loss: 0.0196 - val_accuracy: 0.8913\n","Epoch 169/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0204 - accuracy: 0.8861 - val_loss: 0.0195 - val_accuracy: 0.8916\n","Epoch 170/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0204 - accuracy: 0.8864 - val_loss: 0.0195 - val_accuracy: 0.8916\n","Epoch 171/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0203 - accuracy: 0.8867 - val_loss: 0.0194 - val_accuracy: 0.8917\n","Epoch 172/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0202 - accuracy: 0.8870 - val_loss: 0.0193 - val_accuracy: 0.8924\n","Epoch 173/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0202 - accuracy: 0.8872 - val_loss: 0.0193 - val_accuracy: 0.8925\n","Epoch 174/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0201 - accuracy: 0.8875 - val_loss: 0.0192 - val_accuracy: 0.8926\n","Epoch 175/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0200 - accuracy: 0.8878 - val_loss: 0.0192 - val_accuracy: 0.8926\n","Epoch 176/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0200 - accuracy: 0.8880 - val_loss: 0.0191 - val_accuracy: 0.8927\n","Epoch 177/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0199 - accuracy: 0.8883 - val_loss: 0.0190 - val_accuracy: 0.8932\n","Epoch 178/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0199 - accuracy: 0.8885 - val_loss: 0.0190 - val_accuracy: 0.8934\n","Epoch 179/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0198 - accuracy: 0.8886 - val_loss: 0.0189 - val_accuracy: 0.8934\n","Epoch 180/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0198 - accuracy: 0.8888 - val_loss: 0.0189 - val_accuracy: 0.8936\n","Epoch 181/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0197 - accuracy: 0.8890 - val_loss: 0.0188 - val_accuracy: 0.8938\n","Epoch 182/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0196 - accuracy: 0.8891 - val_loss: 0.0188 - val_accuracy: 0.8939\n","Epoch 183/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0196 - accuracy: 0.8892 - val_loss: 0.0187 - val_accuracy: 0.8944\n","Epoch 184/200\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0195 - accuracy: 0.8896 - val_loss: 0.0187 - val_accuracy: 0.8941\n","Epoch 185/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0195 - accuracy: 0.8897 - val_loss: 0.0186 - val_accuracy: 0.8945\n","Epoch 186/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0194 - accuracy: 0.8899 - val_loss: 0.0186 - val_accuracy: 0.8947\n","Epoch 187/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0194 - accuracy: 0.8901 - val_loss: 0.0185 - val_accuracy: 0.8948\n","Epoch 188/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0193 - accuracy: 0.8903 - val_loss: 0.0185 - val_accuracy: 0.8950\n","Epoch 189/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0193 - accuracy: 0.8905 - val_loss: 0.0184 - val_accuracy: 0.8952\n","Epoch 190/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0192 - accuracy: 0.8905 - val_loss: 0.0184 - val_accuracy: 0.8955\n","Epoch 191/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0192 - accuracy: 0.8908 - val_loss: 0.0183 - val_accuracy: 0.8958\n","Epoch 192/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0191 - accuracy: 0.8909 - val_loss: 0.0183 - val_accuracy: 0.8957\n","Epoch 193/200\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0191 - accuracy: 0.8910 - val_loss: 0.0182 - val_accuracy: 0.8959\n","Epoch 194/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0190 - accuracy: 0.8913 - val_loss: 0.0182 - val_accuracy: 0.8961\n","Epoch 195/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0190 - accuracy: 0.8913 - val_loss: 0.0181 - val_accuracy: 0.8964\n","Epoch 196/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0189 - accuracy: 0.8915 - val_loss: 0.0181 - val_accuracy: 0.8964\n","Epoch 197/200\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0189 - accuracy: 0.8917 - val_loss: 0.0180 - val_accuracy: 0.8964\n","Epoch 198/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0188 - accuracy: 0.8918 - val_loss: 0.0180 - val_accuracy: 0.8965\n","Epoch 199/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0188 - accuracy: 0.8921 - val_loss: 0.0179 - val_accuracy: 0.8966\n","Epoch 200/200\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0188 - accuracy: 0.8923 - val_loss: 0.0179 - val_accuracy: 0.8968\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ffa03145f70>"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["My last tested model had changed number of batch size."],"metadata":{"id":"fExM4JMTeMez"}},{"cell_type":"markdown","source":["#Summary"],"metadata":{"id":"Uv_N4UyzeWXr"}},{"cell_type":"markdown","source":["# Basic model\n","During my tests I complile 5 diffrent models, every one with number in its name had one variable changed (one of the hyperparamiters etc.). After that, I compare each of this models to my basic model. Basic model is the same model that we build on our laboratory classes (the second one, March 8th). The changed variables were: learning rate, number of neurons in dense, type of neurons in dense, and batch size.\n","Our basic model have parameters as followed, in order: 0.01, 64, sigmoid and 128. After comparing this models in pairs, based on this one parameter which was changed, I wrote some observations."],"metadata":{"id":"slUu-kzEenLZ"}},{"cell_type":"markdown","source":["#First changed model - learning rate\n","In my first model (model1) I changed learning rate from 0.01 to 0.1 (so this rate is 10 times bigger). The diffrence in accuracy was about 10 precentage points, but the main problem, that can be here is the size of our steps. This can be misleading that we think that our model is learning fast, but it can 'overstep' the good way to learn. This thing occure in situations when I established rate at higher levels (like 0.6 or 0.7, not included in this notebook). From what I saw in my tests, the higher rate, the better accuracy, but we have to limit this rate at level of 0.4 or 0.5 (of course, I didn't run too many tests, it's my observation)."],"metadata":{"id":"j1MtzwiqRabg"}},{"cell_type":"markdown","source":["# Second model - number of neurons\n","In this model I was changing the number of neurons in a layer. In presented compilation the rate did not changed much (about 2 precentage points). When it comes to this number, as was said on our laboratories, in this case it is really important to get this kind of feeling about it. In some of sources that I have read, it says that the number of neurons shoud be about 0.6 - 0.7 of size of the output layer. In this case apart from number of neurons, it is important to add optimal number of hidden layers, and both numbers can vary. Despite running few test about this parameter, I unfortunately didn't observe any pattern about number of neurons and efficency of model."],"metadata":{"id":"QhoF2fZ2Ub41"}},{"cell_type":"markdown","source":["# Third model - type of neurons\n","In this case I only compared 'sigmoid' and 'relu', becouse on our laboratiories we only used this two types (one on 2nd and the other on 3rd). In model with the changed variable the accuracy was higer and the growth of it was different. In relu model the first steps were much bigger and it kinda slowed when it comes to later epochs. I may be wrong, but it maybe the same problem as in learning rate with skipping some steps, which can lead to wrong solution of problem. I am not an expert in this field, so I only made this one observation in this case."],"metadata":{"id":"2W7yHxDkW_IZ"}},{"cell_type":"markdown","source":["# Fourth model - batch size\n","In my last showed example I changed batch size - in this notebook I modified it from 128 to 64. The batch size, as it is written in some sources, should vary based on training samples given to our model. In showed case the accuracy had grown, but not by a big number. While writing this summary I spotted my mistake, becouse as I wrote, the number should be changed related to samples. But still, the batch size should be smaller than number of samples, so this test kinda give some answers that can give us some information. In this case, the smaller number, the less memory needed."],"metadata":{"id":"3qT02O2aYqMl"}},{"cell_type":"markdown","source":["# Conclusion\n","I wrote eariler, I am not an expert in this field, so I don't know if my test give any good informations (or is it just noise ;) ). My first thought was to combine this parameters to create the best model, by after some time and some rethinking I realised it is not that easy. We don't really know how would variables work with each other util the test. We can't really say that created model will work in every situation and on every type of data. Every choice of every parameter is importatnt becouse it can change the whole process. What work for one kind of data, will not necesserily work for other one. In many cases we have to get that feeling about completing the variables to create the best possible model in our situatuion."],"metadata":{"id":"IOcH6HR0a6nY"}}]}